{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dGseP1Z5yv4S",
        "outputId": "08395a0b-f38f-4571-8f34-66d0c29f93d9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "plt.rcParams.update({\n",
        "    \"figure.facecolor\":\"black\",\n",
        "    \"axes.facecolor\":\"black\",\n",
        "    \"axes.edgecolor\":\"orange\",\n",
        "    \"xtick.color\":\"red\",\n",
        "    \"ytick.color\":\"yellow\",\n",
        "    \"legend.labelcolor\":\"linecolor\"\n",
        "})\n",
        "plt.plot(range(10))\n",
        "# Creating known parameters\n",
        "weight = .7\n",
        "bias = .3\n",
        "# Craet data\n",
        "start = 0\n",
        "end = 1\n",
        "step = .02\n",
        "X = torch.arange(start, end, step).unsqueeze(dim=1)\n",
        "y = weight*X+bias\n",
        "X[:10], y[:10]\n",
        "\n",
        "# Creating train/test split\n",
        "train_split=int(.8*len(X)) # Hence 80% data is used for training set\n",
        "X_train, y_train=X[:train_split], y[:train_split]\n",
        "X_test, y_test=X[train_split:], y[train_split:]\n",
        "len(X_train), len(y_train), len(X_test), len(y_test)\n",
        "\n",
        "# Now creating a function to visualize it\n",
        "def plot_predictions(train_data=X_train, train_labels=y_train, test_data=X_test, test_labels=y_test, predictions=None):\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    #plotting trainnnin data in blue\n",
        "    plt.scatter(train_data, train_labels, c=\"b\", s=4, label=\"Training Data\")\n",
        "    #plotting test data in yello\n",
        "    plt.scatter(test_data, test_labels, c=\"y\", s=4, label=\"TEst Data\")\n",
        "    if predictions is not None:\n",
        "        # plotting that predictions were made on red color\n",
        "        plt.scatter(test_data, predictions, c=\"r\", s=4, label=\"Predictions\")\n",
        "    plt.legend(prop={\"size\":14})\n",
        "plot_predictions()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ddIpall7gpHp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearRegressionoModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.weights = nn.Parameter(torch.randn(1, dtype=torch.float), requires_grad=True)\n",
        "    self.bias = nn.Parameter(torch.randn(1, dtype=torch.float), requires_grad=True)\n",
        "  def forward(self, x:torch.Tensor)->torch.Tensor:\n",
        "    return self.weights*x + self.bias\n",
        "# Setting manual seed since nn.Parameter are arandomly initialized\n",
        "torch.manual_seed(42)\n",
        "model_0=LinearRegressionoModel()\n",
        "list(model_0.parameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UN_WoiN2y1c0",
        "outputId": "42190994-b6bb-4ea8-a696-a1201813207f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([0.3367], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([0.1288], requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List named Parameters\n",
        "model_0.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WQ7ppIo2IWa",
        "outputId": "3b7c1de8-c551-4eea-9bc9-be399bd962ab"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weights', tensor([0.3367])), ('bias', tensor([0.1288]))])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's make predictions using torch.inference_mode() method\n",
        "with torch.inference_mode():\n",
        "  y_preds = model_0(X_test)"
      ],
      "metadata": {
        "id": "bjAbncuL2R7s"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking and prnting the predictinos values\n",
        "print(f\"Number of testing samples:{len(X_test)}\")\n",
        "print(f\"Number of predictions made:{len(y_preds)}\")\n",
        "print(f\"Predicted values:\\n{y_preds}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPlS1V4rDiKQ",
        "outputId": "39d7fc00-afb8-4629-f971-3061542cedcd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of testing samples:10\n",
            "Number of predictions made:10\n",
            "Predicted values:\n",
            "tensor([[0.3982],\n",
            "        [0.4049],\n",
            "        [0.4116],\n",
            "        [0.4184],\n",
            "        [0.4251],\n",
            "        [0.4318],\n",
            "        [0.4386],\n",
            "        [0.4453],\n",
            "        [0.4520],\n",
            "        [0.4588]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_predictions(predictions=y_preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "2GR0PfSGEH2o",
        "outputId": "6868e0c1-c03c-4f7d-9609-33ebaefb42e7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test-y_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsanQb24EOVN",
        "outputId": "0b219296-e4fe-49d5-ab7f-7926f119736c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4618],\n",
              "        [0.4691],\n",
              "        [0.4764],\n",
              "        [0.4836],\n",
              "        [0.4909],\n",
              "        [0.4982],\n",
              "        [0.5054],\n",
              "        [0.5127],\n",
              "        [0.5200],\n",
              "        [0.5272]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the loss function\n",
        "loss_fn=nn.L1Loss() # MAE loss is same as L1Loss\n",
        "# Creating the optimizer\n",
        "optimizer = torch.optim.SGD(params=model_0.parameters(), # parameters of target model to optimize\n",
        "                            lr=.01)#learning rate"
      ],
      "metadata": {
        "id": "JbDQIexmEVEX"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "epochs = 300\n",
        "# creating tmpty list for tracking values\n",
        "train_loss_values = []\n",
        "test_loss_values = []\n",
        "epoch_count = []\n",
        "for epoch in range(epochs):\n",
        "  ###Trainning\n",
        "  model_0.train()\n",
        "  y_pred = model_0(X_train)\n",
        "  print(y_pred)\n",
        "  loss = loss_fn(y_pred, y_train)\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  model_0.eval()\n",
        "  with torch.inference_mode():\n",
        "    test_pred=model_0(X_test)\n",
        "    test_loss=loss_fn(test_pred, y_test.type(torch.float))\n",
        "    if epoch%10==0:\n",
        "      epoch_count.append(epoch)\n",
        "      train_loss_values.append(loss.detach().numpy())\n",
        "      test_loss_values.append(test_loss.detach().numpy())\n",
        "      print(f\"Epoch: {epoch} | MAE Train Loss: {loss} | MAE Test Loss: {test_loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpNqsQh8hYVO",
        "outputId": "2fbf9bec-3091-47ee-ea00-34ebfa2e5afb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "        [0.4661],\n",
            "        [0.4800],\n",
            "        [0.4939],\n",
            "        [0.5078],\n",
            "        [0.5218],\n",
            "        [0.5357],\n",
            "        [0.5496],\n",
            "        [0.5635],\n",
            "        [0.5774],\n",
            "        [0.5913],\n",
            "        [0.6052],\n",
            "        [0.6191],\n",
            "        [0.6330],\n",
            "        [0.6469],\n",
            "        [0.6608],\n",
            "        [0.6747],\n",
            "        [0.6886],\n",
            "        [0.7025],\n",
            "        [0.7164],\n",
            "        [0.7303],\n",
            "        [0.7442],\n",
            "        [0.7581],\n",
            "        [0.7720],\n",
            "        [0.7859],\n",
            "        [0.7998],\n",
            "        [0.8137],\n",
            "        [0.8276],\n",
            "        [0.8415]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3093],\n",
            "        [0.3233],\n",
            "        [0.3373],\n",
            "        [0.3513],\n",
            "        [0.3652],\n",
            "        [0.3792],\n",
            "        [0.3932],\n",
            "        [0.4072],\n",
            "        [0.4212],\n",
            "        [0.4351],\n",
            "        [0.4491],\n",
            "        [0.4631],\n",
            "        [0.4771],\n",
            "        [0.4911],\n",
            "        [0.5050],\n",
            "        [0.5190],\n",
            "        [0.5330],\n",
            "        [0.5470],\n",
            "        [0.5610],\n",
            "        [0.5749],\n",
            "        [0.5889],\n",
            "        [0.6029],\n",
            "        [0.6169],\n",
            "        [0.6309],\n",
            "        [0.6448],\n",
            "        [0.6588],\n",
            "        [0.6728],\n",
            "        [0.6868],\n",
            "        [0.7008],\n",
            "        [0.7147],\n",
            "        [0.7287],\n",
            "        [0.7427],\n",
            "        [0.7567],\n",
            "        [0.7707],\n",
            "        [0.7847],\n",
            "        [0.7986],\n",
            "        [0.8126],\n",
            "        [0.8266],\n",
            "        [0.8406],\n",
            "        [0.8546]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.2993],\n",
            "        [0.3132],\n",
            "        [0.3271],\n",
            "        [0.3410],\n",
            "        [0.3549],\n",
            "        [0.3688],\n",
            "        [0.3827],\n",
            "        [0.3966],\n",
            "        [0.4105],\n",
            "        [0.4244],\n",
            "        [0.4383],\n",
            "        [0.4522],\n",
            "        [0.4661],\n",
            "        [0.4800],\n",
            "        [0.4939],\n",
            "        [0.5078],\n",
            "        [0.5218],\n",
            "        [0.5357],\n",
            "        [0.5496],\n",
            "        [0.5635],\n",
            "        [0.5774],\n",
            "        [0.5913],\n",
            "        [0.6052],\n",
            "        [0.6191],\n",
            "        [0.6330],\n",
            "        [0.6469],\n",
            "        [0.6608],\n",
            "        [0.6747],\n",
            "        [0.6886],\n",
            "        [0.7025],\n",
            "        [0.7164],\n",
            "        [0.7303],\n",
            "        [0.7442],\n",
            "        [0.7581],\n",
            "        [0.7720],\n",
            "        [0.7859],\n",
            "        [0.7998],\n",
            "        [0.8137],\n",
            "        [0.8276],\n",
            "        [0.8415]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3093],\n",
            "        [0.3233],\n",
            "        [0.3373],\n",
            "        [0.3513],\n",
            "        [0.3652],\n",
            "        [0.3792],\n",
            "        [0.3932],\n",
            "        [0.4072],\n",
            "        [0.4212],\n",
            "        [0.4351],\n",
            "        [0.4491],\n",
            "        [0.4631],\n",
            "        [0.4771],\n",
            "        [0.4911],\n",
            "        [0.5050],\n",
            "        [0.5190],\n",
            "        [0.5330],\n",
            "        [0.5470],\n",
            "        [0.5610],\n",
            "        [0.5749],\n",
            "        [0.5889],\n",
            "        [0.6029],\n",
            "        [0.6169],\n",
            "        [0.6309],\n",
            "        [0.6448],\n",
            "        [0.6588],\n",
            "        [0.6728],\n",
            "        [0.6868],\n",
            "        [0.7008],\n",
            "        [0.7147],\n",
            "        [0.7287],\n",
            "        [0.7427],\n",
            "        [0.7567],\n",
            "        [0.7707],\n",
            "        [0.7847],\n",
            "        [0.7986],\n",
            "        [0.8126],\n",
            "        [0.8266],\n",
            "        [0.8406],\n",
            "        [0.8546]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.2993],\n",
            "        [0.3132],\n",
            "        [0.3271],\n",
            "        [0.3410],\n",
            "        [0.3549],\n",
            "        [0.3688],\n",
            "        [0.3827],\n",
            "        [0.3966],\n",
            "        [0.4105],\n",
            "        [0.4244],\n",
            "        [0.4383],\n",
            "        [0.4522],\n",
            "        [0.4661],\n",
            "        [0.4800],\n",
            "        [0.4939],\n",
            "        [0.5078],\n",
            "        [0.5218],\n",
            "        [0.5357],\n",
            "        [0.5496],\n",
            "        [0.5635],\n",
            "        [0.5774],\n",
            "        [0.5913],\n",
            "        [0.6052],\n",
            "        [0.6191],\n",
            "        [0.6330],\n",
            "        [0.6469],\n",
            "        [0.6608],\n",
            "        [0.6747],\n",
            "        [0.6886],\n",
            "        [0.7025],\n",
            "        [0.7164],\n",
            "        [0.7303],\n",
            "        [0.7442],\n",
            "        [0.7581],\n",
            "        [0.7720],\n",
            "        [0.7859],\n",
            "        [0.7998],\n",
            "        [0.8137],\n",
            "        [0.8276],\n",
            "        [0.8415]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3093],\n",
            "        [0.3233],\n",
            "        [0.3373],\n",
            "        [0.3513],\n",
            "        [0.3652],\n",
            "        [0.3792],\n",
            "        [0.3932],\n",
            "        [0.4072],\n",
            "        [0.4212],\n",
            "        [0.4351],\n",
            "        [0.4491],\n",
            "        [0.4631],\n",
            "        [0.4771],\n",
            "        [0.4911],\n",
            "        [0.5050],\n",
            "        [0.5190],\n",
            "        [0.5330],\n",
            "        [0.5470],\n",
            "        [0.5610],\n",
            "        [0.5749],\n",
            "        [0.5889],\n",
            "        [0.6029],\n",
            "        [0.6169],\n",
            "        [0.6309],\n",
            "        [0.6448],\n",
            "        [0.6588],\n",
            "        [0.6728],\n",
            "        [0.6868],\n",
            "        [0.7008],\n",
            "        [0.7147],\n",
            "        [0.7287],\n",
            "        [0.7427],\n",
            "        [0.7567],\n",
            "        [0.7707],\n",
            "        [0.7847],\n",
            "        [0.7986],\n",
            "        [0.8126],\n",
            "        [0.8266],\n",
            "        [0.8406],\n",
            "        [0.8546]], grad_fn=<AddBackward0>)\n",
            "Epoch: 180 | MAE Train Loss: 0.008932482451200485 | MAE Test Loss: 0.005023092031478882\n",
            "tensor([[0.2993],\n",
            "        [0.3132],\n",
            "        [0.3271],\n",
            "        [0.3410],\n",
            "        [0.3549],\n",
            "        [0.3688],\n",
            "        [0.3827],\n",
            "        [0.3966],\n",
            "        [0.4105],\n",
            "        [0.4244],\n",
            "        [0.4383],\n",
            "        [0.4522],\n",
            "        [0.4661],\n",
            "        [0.4800],\n",
            "        [0.4939],\n",
            "        [0.5078],\n",
            "        [0.5218],\n",
            "        [0.5357],\n",
            "        [0.5496],\n",
            "        [0.5635],\n",
            "        [0.5774],\n",
            "        [0.5913],\n",
            "        [0.6052],\n",
            "        [0.6191],\n",
            "        [0.6330],\n",
            "        [0.6469],\n",
            "        [0.6608],\n",
            "        [0.6747],\n",
            "        [0.6886],\n",
            "        [0.7025],\n",
            "        [0.7164],\n",
            "        [0.7303],\n",
            "        [0.7442],\n",
            "        [0.7581],\n",
            "        [0.7720],\n",
            "        [0.7859],\n",
            "        [0.7998],\n",
            "        [0.8137],\n",
            "        [0.8276],\n",
            "        [0.8415]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3093],\n",
            "        [0.3233],\n",
            "        [0.3373],\n",
            "        [0.3513],\n",
            "        [0.3652],\n",
            "        [0.3792],\n",
            "        [0.3932],\n",
            "        [0.4072],\n",
            "        [0.4212],\n",
            "        [0.4351],\n",
            "        [0.4491],\n",
            "        [0.4631],\n",
            "        [0.4771],\n",
            "        [0.4911],\n",
            "        [0.5050],\n",
            "        [0.5190],\n",
            "        [0.5330],\n",
            "        [0.5470],\n",
            "        [0.5610],\n",
            "        [0.5749],\n",
            "        [0.5889],\n",
            "        [0.6029],\n",
            "        [0.6169],\n",
            "        [0.6309],\n",
            "        [0.6448],\n",
            "        [0.6588],\n",
            "        [0.6728],\n",
            "        [0.6868],\n",
            "        [0.7008],\n",
            "        [0.7147],\n",
            "        [0.7287],\n",
            "        [0.7427],\n",
            "        [0.7567],\n",
            "        [0.7707],\n",
            "        [0.7847],\n",
            "        [0.7986],\n",
            "        [0.8126],\n",
            "        [0.8266],\n",
            "        [0.8406],\n",
            "        [0.8546]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.2993],\n",
            "        [0.3132],\n",
            "        [0.3271],\n",
            "        [0.3410],\n",
            "        [0.3549],\n",
            "        [0.3688],\n",
            "        [0.3827],\n",
            "        [0.3966],\n",
            "        [0.4105],\n",
            "        [0.4244],\n",
            "        [0.4383],\n",
            "        [0.4522],\n",
            "        [0.4661],\n",
            "        [0.4800],\n",
            "        [0.4939],\n",
            "        [0.5078],\n",
            "        [0.5218],\n",
            "        [0.5357],\n",
            "        [0.5496],\n",
            "        [0.5635],\n",
            "        [0.5774],\n",
            "        [0.5913],\n",
            "        [0.6052],\n",
            "        [0.6191],\n",
            "        [0.6330],\n",
            "        [0.6469],\n",
            "        [0.6608],\n",
            "        [0.6747],\n",
            "        [0.6886],\n",
            "        [0.7025],\n",
            "        [0.7164],\n",
            "        [0.7303],\n",
            "        [0.7442],\n",
            "        [0.7581],\n",
            "        [0.7720],\n",
            "        [0.7859],\n",
            "        [0.7998],\n",
            "        [0.8137],\n",
            "        [0.8276],\n",
            "        [0.8415]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3093],\n",
            "        [0.3233],\n",
            "        [0.3373],\n",
            "        [0.3513],\n",
            "        [0.3652],\n",
            "        [0.3792],\n",
            "        [0.3932],\n",
            "        [0.4072],\n",
            "        [0.4212],\n",
            "        [0.4351],\n",
            "        [0.4491],\n",
            "        [0.4631],\n",
            "        [0.4771],\n",
            "        [0.4911],\n",
            "        [0.5050],\n",
            "        [0.5190],\n",
            "        [0.5330],\n",
            "        [0.5470],\n",
            "        [0.5610],\n",
            "        [0.5749],\n",
            "        [0.5889],\n",
            "        [0.6029],\n",
            "        [0.6169],\n",
            "        [0.6309],\n",
            "        [0.6448],\n",
            "        [0.6588],\n",
            "        [0.6728],\n",
            "        [0.6868],\n",
            "        [0.7008],\n",
            "        [0.7147],\n",
            "        [0.7287],\n",
            "        [0.7427],\n",
            "        [0.7567],\n",
            "        [0.7707],\n",
            "        [0.7847],\n",
            "        [0.7986],\n",
            "        [0.8126],\n",
            "        [0.8266],\n",
            "        [0.8406],\n",
            "        [0.8546]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.2993],\n",
            "        [0.3132],\n",
            "        [0.3271],\n",
            "        [0.3410],\n",
            "        [0.3549],\n",
            "        [0.3688],\n",
            "        [0.3827],\n",
            "        [0.3966],\n",
            "        [0.4105],\n",
            "        [0.4244],\n",
            "        [0.4383],\n",
            "        [0.4522],\n",
            "        [0.4661],\n",
            "        [0.4800],\n",
            "        [0.4939],\n",
            "        [0.5078],\n",
            "        [0.5218],\n",
            "        [0.5357],\n",
            "        [0.5496],\n",
            "        [0.5635],\n",
            "        [0.5774],\n",
            "        [0.5913],\n",
            "        [0.6052],\n",
            "        [0.6191],\n",
            "        [0.6330],\n",
            "        [0.6469],\n",
            "        [0.6608],\n",
            "        [0.6747],\n",
            "        [0.6886],\n",
            "        [0.7025],\n",
            "        [0.7164],\n",
            "        [0.7303],\n",
            "        [0.7442],\n",
            "        [0.7581],\n",
            "        [0.7720],\n",
            "        [0.7859],\n",
            "        [0.7998],\n",
            "        [0.8137],\n",
            "        [0.8276],\n",
            "        [0.8415]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3093],\n",
            "        [0.3233],\n",
            "        [0.3373],\n",
            "        [0.3513],\n",
            "        [0.3652],\n",
            "        [0.3792],\n",
            "        [0.3932],\n",
            "        [0.4072],\n",
            "        [0.4212],\n",
            "        [0.4351],\n",
            "        [0.4491],\n",
            "        [0.4631],\n",
            "        [0.4771],\n",
            "        [0.4911],\n",
            "        [0.5050],\n",
            "        [0.5190],\n",
            "        [0.5330],\n",
            "        [0.5470],\n",
            "        [0.5610],\n",
            "        [0.5749],\n",
            "        [0.5889],\n",
            "        [0.6029],\n",
            "        [0.6169],\n",
            "        [0.6309],\n",
            "        [0.6448],\n",
            "        [0.6588],\n",
            "        [0.6728],\n",
            "        [0.6868],\n",
            "        [0.7008],\n",
            "        [0.7147],\n",
            "        [0.7287],\n",
            "        [0.7427],\n",
            "        [0.7567],\n",
            "        [0.7707],\n",
            "        [0.7847],\n",
            "        [0.7986],\n",
            "        [0.8126],\n",
            "        [0.8266],\n",
            "        [0.8406],\n",
            "        [0.8546]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.2993],\n",
            "        [0.3132],\n",
            "        [0.3271],\n",
            "        [0.3410],\n",
            "        [0.3549],\n",
            "        [0.3688],\n",
            "        [0.3827],\n",
            "        [0.3966],\n",
            "        [0.4105],\n",
            "        [0.4244],\n",
            "        [0.4383],\n",
            "        [0.4522],\n",
            "        [0.4661],\n",
            "        [0.4800],\n",
            "        [0.4939],\n",
            "        [0.5078],\n",
            "        [0.5218],\n",
            "        [0.5357],\n",
            "        [0.5496],\n",
            "        [0.5635],\n",
            "        [0.5774],\n",
            "        [0.5913],\n",
            "        [0.6052],\n",
            "        [0.6191],\n",
            "        [0.6330],\n",
            "        [0.6469],\n",
            "        [0.6608],\n",
            "        [0.6747],\n",
            "        [0.6886],\n",
            "        [0.7025],\n",
            "        [0.7164],\n",
            "        [0.7303],\n",
            "        [0.7442],\n",
            "        [0.7581],\n",
            "        [0.7720],\n",
            "        [0.7859],\n",
            "        [0.7998],\n",
            "        [0.8137],\n",
            "        [0.8276],\n",
            "        [0.8415]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3093],\n",
            "        [0.3233],\n",
            "        [0.3373],\n",
            "        [0.3513],\n",
            "        [0.3652],\n",
            "        [0.3792],\n",
            "        [0.3932],\n",
            "        [0.4072],\n",
            "        [0.4212],\n",
            "        [0.4351],\n",
            "        [0.4491],\n",
            "        [0.4631],\n",
            "        [0.4771],\n",
            "        [0.4911],\n",
            "        [0.5050],\n",
            "        [0.5190],\n",
            "        [0.5330],\n",
            "        [0.5470],\n",
            "        [0.5610],\n",
            "        [0.5749],\n",
            "        [0.5889],\n",
            "        [0.6029],\n",
            "        [0.6169],\n",
            "        [0.6309],\n",
            "        [0.6448],\n",
            "        [0.6588],\n",
            "        [0.6728],\n",
            "        [0.6868],\n",
            "        [0.7008],\n",
            "        [0.7147],\n",
            "        [0.7287],\n",
            "        [0.7427],\n",
            "        [0.7567],\n",
            "        [0.7707],\n",
            "        [0.7847],\n",
            "        [0.7986],\n",
            "        [0.8126],\n",
            "        [0.8266],\n",
            "        [0.8406],\n",
            "        [0.8546]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.2993],\n",
            "        [0.3132],\n",
            "        [0.3271],\n",
            "        [0.3410],\n",
            "        [0.3549],\n",
            "        [0.3688],\n",
            "        [0.3827],\n",
            "        [0.3966],\n",
            "        [0.4105],\n",
            "        [0.4244],\n",
            "        [0.4383],\n",
            "        [0.4522],\n",
            "        [0.4661],\n",
            "        [0.4800],\n",
            "        [0.4939],\n",
            "        [0.5078],\n",
            "        [0.5218],\n",
            "        [0.5357],\n",
            "        [0.5496],\n",
            "        [0.5635],\n",
            "        [0.5774],\n",
            "        [0.5913],\n",
            "        [0.6052],\n",
            "        [0.6191],\n",
            "        [0.6330],\n",
            "        [0.6469],\n",
            "        [0.6608],\n",
            "        [0.6747],\n",
            "        [0.6886],\n",
            "        [0.7025],\n",
            "        [0.7164],\n",
            "        [0.7303],\n",
            "        [0.7442],\n",
            "        [0.7581],\n",
            "        [0.7720],\n",
            "        [0.7859],\n",
            "        [0.7998],\n",
            "        [0.8137],\n",
            "        [0.8276],\n",
            "        [0.8415]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3093],\n",
            "        [0.3233],\n",
            "        [0.3373],\n",
            "        [0.3513],\n",
            "        [0.3652],\n",
            "        [0.3792],\n",
            "        [0.3932],\n",
            "        [0.4072],\n",
            "        [0.4212],\n",
            "        [0.4351],\n",
            "        [0.4491],\n",
            "        [0.4631],\n",
            "        [0.4771],\n",
            "        [0.4911],\n",
            "        [0.5050],\n",
            "        [0.5190],\n",
            "        [0.5330],\n",
            "        [0.5470],\n",
            "        [0.5610],\n",
            "        [0.5749],\n",
            "        [0.5889],\n",
            "        [0.6029],\n",
            "        [0.6169],\n",
            "        [0.6309],\n",
            "        [0.6448],\n",
            "        [0.6588],\n",
            "        [0.6728],\n",
            "        [0.6868],\n",
            "        [0.7008],\n",
            "        [0.7147],\n",
            "        [0.7287],\n",
            "        [0.7427],\n",
            "        [0.7567],\n",
            "        [0.7707],\n",
            "        [0.7847],\n",
            "        [0.7986],\n",
            "        [0.8126],\n",
            "        [0.8266],\n",
            "        [0.8406],\n",
            "        [0.8546]], grad_fn=<AddBackward0>)\n",
            "Epoch: 190 | MAE Train Loss: 0.008932482451200485 | MAE Test Loss: 0.005023092031478882\n",
            "tensor([[0.2993],\n",
            "        [0.3132],\n",
            "        [0.3271],\n",
            "        [0.3410],\n",
            "        [0.3549],\n",
            "        [0.3688],\n",
            "        [0.3827],\n",
            "        [0.3966],\n",
            "        [0.4105],\n",
            "        [0.4244],\n",
            "        [0.4383],\n",
            "        [0.4522],\n",
            "        [0.4661],\n",
            "        [0.4800],\n",
            "        [0.4939],\n",
            "        [0.5078],\n",
            "        [0.5218],\n",
            "        [0.5357],\n",
            "        [0.5496],\n",
            "        [0.5635],\n",
            "        [0.5774],\n",
            "        [0.5913],\n",
            "        [0.6052],\n",
            "        [0.6191],\n",
            "        [0.6330],\n",
            "        [0.6469],\n",
            "        [0.6608],\n",
            "        [0.6747],\n",
            "        [0.6886],\n",
            "        [0.7025],\n",
            "        [0.7164],\n",
            "        [0.7303],\n",
            "        [0.7442],\n",
            "        [0.7581],\n",
            "        [0.7720],\n",
            "        [0.7859],\n",
            "        [0.7998],\n",
            "        [0.8137],\n",
            "        [0.8276],\n",
            "        [0.8415]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3093],\n",
            "        [0.3233],\n",
            "        [0.3373],\n",
            "        [0.3513],\n",
            "        [0.3652],\n",
            "        [0.3792],\n",
            "        [0.3932],\n",
            "        [0.4072],\n",
            "        [0.4212],\n",
            "        [0.4351],\n",
            "        [0.4491],\n",
            "        [0.4631],\n",
            "        [0.4771],\n",
            "        [0.4911],\n",
            "        [0.5050],\n",
            "        [0.5190],\n",
            "        [0.5330],\n",
            "        [0.5470],\n",
            "        [0.5610],\n",
            "        [0.5749],\n",
            "        [0.5889],\n",
            "        [0.6029],\n",
            "        [0.6169],\n",
            "        [0.6309],\n",
            "        [0.6448],\n",
            "        [0.6588],\n",
            "        [0.6728],\n",
            "        [0.6868],\n",
            "        [0.7008],\n",
            "        [0.7147],\n",
            "        [0.7287],\n",
            "        [0.7427],\n",
            "        [0.7567],\n",
            "        [0.7707],\n",
            "        [0.7847],\n",
            "        [0.7986],\n",
            "        [0.8126],\n",
            "        [0.8266],\n",
            "        [0.8406],\n",
            "        [0.8546]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.2993],\n",
            "        [0.3132],\n",
            "        [0.3271],\n",
            "        [0.3410],\n",
            "        [0.3549],\n",
            "        [0.3688],\n",
            "        [0.3827],\n",
            "        [0.3966],\n",
            "        [0.4105],\n",
            "        [0.4244],\n",
            "        [0.4383],\n",
            "        [0.4522],\n",
            "        [0.4661],\n",
            "        [0.4800],\n",
            "        [0.4939],\n",
            "        [0.5078],\n",
            "        [0.5218],\n",
            "        [0.5357],\n",
            "        [0.5496],\n",
            "        [0.5635],\n",
            "        [0.5774],\n",
            "        [0.5913],\n",
            "        [0.6052],\n",
            "        [0.6191],\n",
            "        [0.6330],\n",
            "        [0.6469],\n",
            "        [0.6608],\n",
            "        [0.6747],\n",
            "        [0.6886],\n",
            "        [0.7025],\n",
            "        [0.7164],\n",
            "        [0.7303],\n",
            "        [0.7442],\n",
            "        [0.7581],\n",
            "        [0.7720],\n",
            "        [0.7859],\n",
            "        [0.7998],\n",
            "        [0.8137],\n",
            "        [0.8276],\n",
            "        [0.8415]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3093],\n",
            "        [0.3233],\n",
            "        [0.3373],\n",
            "        [0.3513],\n",
            "        [0.3652],\n",
            "        [0.3792],\n",
            "        [0.3932],\n",
            "        [0.4072],\n",
            "        [0.4212],\n",
            "        [0.4351],\n",
            "        [0.4491],\n",
            "        [0.4631],\n",
            "        [0.4771],\n",
            "        [0.4911],\n",
            "        [0.5050],\n",
            "        [0.5190],\n",
            "        [0.5330],\n",
            "        [0.5470],\n",
            "        [0.5610],\n",
            "        [0.5749],\n",
            "        [0.5889],\n",
            "        [0.6029],\n",
            "        [0.6169],\n",
            "        [0.6309],\n",
            "        [0.6448],\n",
            "        [0.6588],\n",
            "        [0.6728],\n",
            "        [0.6868],\n",
            "        [0.7008],\n",
            "        [0.7147],\n",
            "        [0.7287],\n",
            "        [0.7427],\n",
            "        [0.7567],\n",
            "        [0.7707],\n",
            "        [0.7847],\n",
            "        [0.7986],\n",
            "        [0.8126],\n",
            "        [0.8266],\n",
            "        [0.8406],\n",
            "        [0.8546]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.2993],\n",
            "        [0.3132],\n",
            "        [0.3271],\n",
            "        [0.3410],\n",
            "        [0.3549],\n",
            "        [0.3688],\n",
            "        [0.3827],\n",
            "        [0.3966],\n",
            "        [0.4105],\n",
            "        [0.4244],\n",
            "        [0.4383],\n",
            "        [0.4522],\n",
            "        [0.4661],\n",
            "        [0.4800],\n",
            "        [0.4939],\n",
            "        [0.5078],\n",
            "        [0.5218],\n",
            "        [0.5357],\n",
            "        [0.5496],\n",
            "        [0.5635],\n",
            "        [0.5774],\n",
            "        [0.5913],\n",
            "        [0.6052],\n",
            "        [0.6191],\n",
            "        [0.6330],\n",
            "        [0.6469],\n",
            "        [0.6608],\n",
            "        [0.6747],\n",
            "        [0.6886],\n",
            "        [0.7025],\n",
            "        [0.7164],\n",
            "        [0.7303],\n",
            "        [0.7442],\n",
            "        [0.7581],\n",
            "        [0.7720],\n",
            "        [0.7859],\n",
            "        [0.7998],\n",
            "        [0.8137],\n",
            "        [0.8276],\n",
            "        [0.8415]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3093],\n",
            "        [0.3233],\n",
            "        [0.3373],\n",
            "        [0.3513],\n",
            "        [0.3652],\n",
            "        [0.3792],\n",
            "        [0.3932],\n",
            "        [0.4072],\n",
            "        [0.4212],\n",
            "        [0.4351],\n",
            "        [0.4491],\n",
            "        [0.4631],\n",
            "        [0.4771],\n",
            "        [0.4911],\n",
            "        [0.5050],\n",
            "        [0.5190],\n",
            "        [0.5330],\n",
            "        [0.5470],\n",
            "        [0.5610],\n",
            "        [0.5749],\n",
            "        [0.5889],\n",
            "        [0.6029],\n",
            "        [0.6169],\n",
            "        [0.6309],\n",
            "        [0.6448],\n",
            "        [0.6588],\n",
            "        [0.6728],\n",
            "        [0.6868],\n",
            "        [0.7008],\n",
            "        [0.7147],\n",
            "        [0.7287],\n",
            "        [0.7427],\n",
            "        [0.7567],\n",
            "        [0.7707],\n",
            "        [0.7847],\n",
            "        [0.7986],\n",
            "        [0.8126],\n",
            "        [0.8266],\n",
            "        [0.8406],\n",
            "        [0.8546]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.2993],\n",
            "        [0.3132],\n",
            "        [0.3271],\n",
            "        [0.3410],\n",
            "        [0.3549],\n",
            "        [0.3688],\n",
            "        [0.3827],\n",
            "        [0.3966],\n",
            "        [0.4105],\n",
            "        [0.4244],\n",
            "        [0.4383],\n",
            "        [0.4522],\n",
            "        [0.4661],\n",
            "        [0.4800],\n",
            "        [0.4939],\n",
            "        [0.5078],\n",
            "        [0.5218],\n",
            "        [0.5357],\n",
            "        [0.5496],\n",
            "        [0.5635],\n",
            "        [0.5774],\n",
            "        [0.5913],\n",
            "        [0.6052],\n",
            "        [0.6191],\n",
            "        [0.6330],\n",
            "        [0.6469],\n",
            "        [0.6608],\n",
            "        [0.6747],\n",
            "        [0.6886],\n",
            "        [0.7025],\n",
            "        [0.7164],\n",
            "        [0.7303],\n",
            "        [0.7442],\n",
            "        [0.7581],\n",
            "        [0.7720],\n",
            "        [0.7859],\n",
            "        [0.7998],\n",
            "        [0.8137],\n",
            "        [0.8276],\n",
            "        [0.8415]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3093],\n",
            "        [0.3233],\n",
            "        [0.3373],\n",
            "        [0.3513],\n",
            "        [0.3652],\n",
            "        [0.3792],\n",
            "        [0.3932],\n",
            "        [0.4072],\n",
            "        [0.4212],\n",
            "        [0.4351],\n",
            "        [0.4491],\n",
            "        [0.4631],\n",
            "        [0.4771],\n",
            "        [0.4911],\n",
            "        [0.5050],\n",
            "        [0.5190],\n",
            "        [0.5330],\n",
            "        [0.5470],\n",
            "        [0.5610],\n",
            "        [0.5749],\n",
            "        [0.5889],\n",
            "        [0.6029],\n",
            "        [0.6169],\n",
            "        [0.6309],\n",
            "        [0.6448],\n",
            "        [0.6588],\n",
            "        [0.6728],\n",
            "        [0.6868],\n",
            "        [0.7008],\n",
            "        [0.7147],\n",
            "        [0.7287],\n",
            "        [0.7427],\n",
            "        [0.7567],\n",
            "        [0.7707],\n",
            "        [0.7847],\n",
            "        [0.7986],\n",
            "        [0.8126],\n",
            "        [0.8266],\n",
            "        [0.8406],\n",
            "        [0.8546]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.2993],\n",
            "        [0.3132],\n",
            "        [0.3271],\n",
            "        [0.3410],\n",
            "        [0.3549],\n",
            "        [0.3688],\n",
            "        [0.3827],\n",
            "        [0.3966],\n",
            "        [0.4105],\n",
            "        [0.4244],\n",
            "        [0.4383],\n",
            "        [0.4522],\n",
            "        [0.4661],\n",
            "        [0.4800],\n",
            "        [0.4939],\n",
            "        [0.5078],\n",
            "        [0.5218],\n",
            "        [0.5357],\n",
            "        [0.5496],\n",
            "        [0.5635],\n",
            "        [0.5774],\n",
            "        [0.5913],\n",
            "        [0.6052],\n",
            "        [0.6191],\n",
            "        [0.6330],\n",
            "        [0.6469],\n",
            "        [0.6608],\n",
            "        [0.6747],\n",
            "        [0.6886],\n",
            "        [0.7025],\n",
            "        [0.7164],\n",
            "        [0.7303],\n",
            "        [0.7442],\n",
            "        [0.7581],\n",
            "        [0.7720],\n",
            "        [0.7859],\n",
            "        [0.7998],\n",
            "        [0.8137],\n",
            "        [0.8276],\n",
            "        [0.8415]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3093],\n",
            "        [0.3233],\n",
            "        [0.3373],\n",
            "        [0.3513],\n",
            "        [0.3652],\n",
            "        [0.3792],\n",
            "        [0.3932],\n",
            "        [0.4072],\n",
            "        [0.4212],\n",
            "        [0.4351],\n",
            "        [0.4491],\n",
            "        [0.4631],\n",
            "        [0.4771],\n",
            "        [0.4911],\n",
            "        [0.5050],\n",
            "        [0.5190],\n",
            "        [0.5330],\n",
            "        [0.5470],\n",
            "        [0.5610],\n",
            "        [0.5749],\n",
            "        [0.5889],\n",
            "        [0.6029],\n",
            "        [0.6169],\n",
            "        [0.6309],\n",
            "        [0.6448],\n",
            "        [0.6588],\n",
            "        [0.6728],\n",
            "        [0.6868],\n",
            "        [0.7008],\n",
            "        [0.7147],\n",
            "        [0.7287],\n",
            "        [0.7427],\n",
            "        [0.7567],\n",
            "        [0.7707],\n",
            "        [0.7847],\n",
            "        [0.7986],\n",
            "        [0.8126],\n",
            "        [0.8266],\n",
            "        [0.8406],\n",
            "        [0.8546]], grad_fn=<AddBackward0>)\n",
            "Epoch: 200 | MAE Train Loss: 0.008932482451200485 | MAE Test Loss: 0.005023092031478882\n",
            "tensor([[0.2993],\n",
            "        [0.3132],\n",
            "        [0.3271],\n",
            "        [0.3410],\n",
            "        [0.3549],\n",
            "        [0.3688],\n",
            "        [0.3827],\n",
            "        [0.3966],\n",
            "        [0.4105],\n",
            "        [0.4244],\n",
            "        [0.4383],\n",
            "        [0.4522],\n",
            "        [0.4661],\n",
            "        [0.4800],\n",
            "        [0.4939],\n",
            "        [0.5078],\n",
            "        [0.5218],\n",
            "        [0.5357],\n",
            "        [0.5496],\n",
            "        [0.5635],\n",
            "        [0.5774],\n",
            "        [0.5913],\n",
            "        [0.6052],\n",
            "        [0.6191],\n",
            "        [0.6330],\n",
            "        [0.6469],\n",
            "        [0.6608],\n",
            "        [0.6747],\n",
            "        [0.6886],\n",
            "        [0.7025],\n",
            "        [0.7164],\n",
            "        [0.7303],\n",
            "        [0.7442],\n",
            "        [0.7581],\n",
            "        [0.7720],\n",
            "        [0.7859],\n",
            "        [0.7998],\n",
            "        [0.8137],\n",
            "        [0.8276],\n",
            "        [0.8415]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3093],\n",
            "        [0.3233],\n",
            "        [0.3373],\n",
            "        [0.3513],\n",
            "        [0.3652],\n",
            "        [0.3792],\n",
            "        [0.3932],\n",
            "        [0.4072],\n",
            "        [0.4212],\n",
            "        [0.4351],\n",
            "        [0.4491],\n",
            "        [0.4631],\n",
            "        [0.4771],\n",
            "        [0.4911],\n",
            "        [0.5050],\n",
            "        [0.5190],\n",
            "        [0.5330],\n",
            "        [0.5470],\n",
            "        [0.5610],\n",
            "        [0.5749],\n",
            "        [0.5889],\n",
            "        [0.6029],\n",
            "        [0.6169],\n",
            "        [0.6309],\n",
            "        [0.6448],\n",
            "        [0.6588],\n",
            "        [0.6728],\n",
            "        [0.6868],\n",
            "        [0.7008],\n",
            "        [0.7147],\n",
            "        [0.7287],\n",
            "        [0.7427],\n",
            "        [0.7567],\n",
            "        [0.7707],\n",
            "        [0.7847],\n",
            "        [0.7986],\n",
            "        [0.8126],\n",
            "        [0.8266],\n",
            "        [0.8406],\n",
            "        [0.8546]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.2993],\n",
            "        [0.3132],\n",
            "        [0.3271],\n",
            "        [0.3410],\n",
            "        [0.3549],\n",
            "        [0.3688],\n",
            "        [0.3827],\n",
            "        [0.3966],\n",
            "        [0.4105],\n",
            "        [0.4244],\n",
            "        [0.4383],\n",
            "        [0.4522],\n",
            "        [0.4661],\n",
            "        [0.4800],\n",
            "        [0.4939],\n",
            "        [0.5078],\n",
            "        [0.5218],\n",
            "        [0.5357],\n",
            "        [0.5496],\n",
            "        [0.5635],\n",
            "        [0.5774],\n",
            "        [0.5913],\n",
            "        [0.6052],\n",
            "        [0.6191],\n",
            "        [0.6330],\n",
            "        [0.6469],\n",
            "        [0.6608],\n",
            "        [0.6747],\n",
            "        [0.6886],\n",
            "        [0.7025],\n",
            "        [0.7164],\n",
            "        [0.7303],\n",
            "        [0.7442],\n",
            "        [0.7581],\n",
            "        [0.7720],\n",
            "        [0.7859],\n",
            "        [0.7998],\n",
            "        [0.8137],\n",
            "        [0.8276],\n",
            "        [0.8415]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3093],\n",
            "        [0.3233],\n",
            "        [0.3373],\n",
            "        [0.3513],\n",
            "        [0.3652],\n",
            "        [0.3792],\n",
            "        [0.3932],\n",
            "        [0.4072],\n",
            "        [0.4212],\n",
            "        [0.4351],\n",
            "        [0.4491],\n",
            "        [0.4631],\n",
            "        [0.4771],\n",
            "        [0.4911],\n",
            "        [0.5050],\n",
            "        [0.5190],\n",
            "        [0.5330],\n",
            "        [0.5470],\n",
            "        [0.5610],\n",
            "        [0.5749],\n",
            "        [0.5889],\n",
            "        [0.6029],\n",
            "        [0.6169],\n",
            "        [0.6309],\n",
            "        [0.6448],\n",
            "        [0.6588],\n",
            "        [0.6728],\n",
            "        [0.6868],\n",
            "        [0.7008],\n",
            "        [0.7147],\n",
            "        [0.7287],\n",
            "        [0.7427],\n",
            "        [0.7567],\n",
            "        [0.7707],\n",
            "        [0.7847],\n",
            "        [0.7986],\n",
            "        [0.8126],\n",
            "        [0.8266],\n",
            "        [0.8406],\n",
            "        [0.8546]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.2993],\n",
            "        [0.3132],\n",
            "        [0.3271],\n",
            "        [0.3410],\n",
            "        [0.3549],\n",
            "        [0.3688],\n",
            "        [0.3827],\n",
            "        [0.3966],\n",
            "        [0.4105],\n",
            "        [0.4244],\n",
            "        [0.4383],\n",
            "        [0.4522],\n",
            "        [0.4661],\n",
            "        [0.4800],\n",
            "        [0.4939],\n",
            "        [0.5078],\n",
            "        [0.5218],\n",
            "        [0.5357],\n",
            "        [0.5496],\n",
            "        [0.5635],\n",
            "        [0.5774],\n",
            "        [0.5913],\n",
            "        [0.6052],\n",
            "        [0.6191],\n",
            "        [0.6330],\n",
            "        [0.6469],\n",
            "        [0.6608],\n",
            "        [0.6747],\n",
            "        [0.6886],\n",
            "        [0.7025],\n",
            "        [0.7164],\n",
            "        [0.7303],\n",
            "        [0.7442],\n",
            "        [0.7581],\n",
            "        [0.7720],\n",
            "        [0.7859],\n",
            "        [0.7998],\n",
            "        [0.8137],\n",
            "        [0.8276],\n",
            "        [0.8415]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3093],\n",
            "        [0.3233],\n",
            "        [0.3373],\n",
            "        [0.3513],\n",
            "        [0.3652],\n",
            "        [0.3792],\n",
            "        [0.3932],\n",
            "        [0.4072],\n",
            "        [0.4212],\n",
            "        [0.4351],\n",
            "        [0.4491],\n",
            "        [0.4631],\n",
            "        [0.4771],\n",
            "        [0.4911],\n",
            "        [0.5050],\n",
            "        [0.5190],\n",
            "        [0.5330],\n",
            "        [0.5470],\n",
            "        [0.5610],\n",
            "        [0.5749],\n",
            "        [0.5889],\n",
            "        [0.6029],\n",
            "        [0.6169],\n",
            "        [0.6309],\n",
            "        [0.6448],\n",
            "        [0.6588],\n",
            "        [0.6728],\n",
            "        [0.6868],\n",
            "        [0.7008],\n",
            "        [0.7147],\n",
            "        [0.7287],\n",
            "        [0.7427],\n",
            "        [0.7567],\n",
            "        [0.7707],\n",
            "        [0.7847],\n",
            "        [0.7986],\n",
            "        [0.8126],\n",
            "        [0.8266],\n",
            "        [0.8406],\n",
            "        [0.8546]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.2993],\n",
            "        [0.3132],\n",
            "        [0.3271],\n",
            "        [0.3410],\n",
            "        [0.3549],\n",
            "        [0.3688],\n",
            "        [0.3827],\n",
            "        [0.3966],\n",
            "        [0.4105],\n",
            "        [0.4244],\n",
            "        [0.4383],\n",
            "        [0.4522],\n",
            "        [0.4661],\n",
            "        [0.4800],\n",
            "        [0.4939],\n",
            "        [0.5078],\n",
            "        [0.5218],\n",
            "        [0.5357],\n",
            "        [0.5496],\n",
            "        [0.5635],\n",
            "        [0.5774],\n",
            "        [0.5913],\n",
            "        [0.6052],\n",
            "        [0.6191],\n",
            "        [0.6330],\n",
            "        [0.6469],\n",
            "        [0.6608],\n",
            "        [0.6747],\n",
            "        [0.6886],\n",
            "        [0.7025],\n",
            "        [0.7164],\n",
            "        [0.7303],\n",
            "        [0.7442],\n",
            "        [0.7581],\n",
            "        [0.7720],\n",
            "        [0.7859],\n",
            "        [0.7998],\n",
            "        [0.8137],\n",
            "        [0.8276],\n",
            "        [0.8415]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3093],\n",
            "        [0.3233],\n",
            "        [0.3373],\n",
            "        [0.3513],\n",
            "        [0.3652],\n",
            "        [0.3792],\n",
            "        [0.3932],\n",
            "        [0.4072],\n",
            "        [0.4212],\n",
            "        [0.4351],\n",
            "        [0.4491],\n",
            "        [0.4631],\n",
            "        [0.4771],\n",
            "        [0.4911],\n",
            "        [0.5050],\n",
            "        [0.5190],\n",
            "        [0.5330],\n",
            "        [0.5470],\n",
            "        [0.5610],\n",
            "        [0.5749],\n",
            "        [0.5889],\n",
            "        [0.6029],\n",
            "        [0.6169],\n",
            "        [0.6309],\n",
            "        [0.6448],\n",
            "        [0.6588],\n",
            "        [0.6728],\n",
            "        [0.6868],\n",
            "        [0.7008],\n",
            "        [0.7147],\n",
            "        [0.7287],\n",
            "        [0.7427],\n",
            "        [0.7567],\n",
            "        [0.7707],\n",
            "        [0.7847],\n",
            "        [0.7986],\n",
            "        [0.8126],\n",
            "        [0.8266],\n",
            "        [0.8406],\n",
            "        [0.8546]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.2993],\n",
            "        [0.3132],\n",
            "        [0.3271],\n",
            "        [0.3410],\n",
            "        [0.3549],\n",
            "        [0.3688],\n",
            "        [0.3827],\n",
            "        [0.3966],\n",
            "        [0.4105],\n",
            "        [0.4244],\n",
            "        [0.4383],\n",
            "        [0.4522],\n",
            "        [0.4661],\n",
            "        [0.4800],\n",
            "        [0.4939],\n",
            "        [0.5078],\n",
            "        [0.5218],\n",
            "        [0.5357],\n",
            "        [0.5496],\n",
            "        [0.5635],\n",
            "        [0.5774],\n",
            "        [0.5913],\n",
            "        [0.6052],\n",
            "        [0.6191],\n",
            "        [0.6330],\n",
            "        [0.6469],\n",
            "        [0.6608],\n",
            "        [0.6747],\n",
            "        [0.6886],\n",
            "        [0.7025],\n",
            "        [0.7164],\n",
            "        [0.7303],\n",
            "        [0.7442],\n",
            "        [0.7581],\n",
            "        [0.7720],\n",
            "        [0.7859],\n",
            "        [0.7998],\n",
            "        [0.8137],\n",
            "        [0.8276],\n",
            "        [0.8415]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3093],\n",
            "        [0.3233],\n",
            "        [0.3373],\n",
            "        [0.3513],\n",
            "        [0.3652],\n",
            "        [0.3792],\n",
            "        [0.3932],\n",
            "        [0.4072],\n",
            "        [0.4212],\n",
            "        [0.4351],\n",
            "        [0.4491],\n",
            "        [0.4631],\n",
            "        [0.4771],\n",
            "        [0.4911],\n",
            "        [0.5050],\n",
            "        [0.5190],\n",
            "        [0.5330],\n",
            "        [0.5470],\n",
            "        [0.5610],\n",
            "        [0.5749],\n",
            "        [0.5889],\n",
            "        [0.6029],\n",
            "        [0.6169],\n",
            "        [0.6309],\n",
            "        [0.6448],\n",
            "        [0.6588],\n",
            "        [0.6728],\n",
            "        [0.6868],\n",
            "        [0.7008],\n",
            "        [0.7147],\n",
            "        [0.7287],\n",
            "        [0.7427],\n",
            "        [0.7567],\n",
            "        [0.7707],\n",
            "        [0.7847],\n",
            "        [0.7986],\n",
            "        [0.8126],\n",
            "        [0.8266],\n",
            "        [0.8406],\n",
            "        [0.8546]], grad_fn=<AddBackward0>)\n",
            "Epoch: 210 | MAE Train Loss: 0.008932482451200485 | MAE Test Loss: 0.005023092031478882\n",
            "tensor([[0.2993],\n",
            "        [0.3132],\n",
            "        [0.3271],\n",
            "        [0.3410],\n",
            "        [0.3549],\n",
            "        [0.3688],\n",
            "        [0.3827],\n",
            "        [0.3966],\n",
            "        [0.4105],\n",
            "        [0.4244],\n",
            "        [0.4383],\n",
            "        [0.4522],\n",
            "        [0.4661],\n",
            "        [0.4800],\n",
            "        [0.4939],\n",
            "        [0.5078],\n",
            "        [0.5218],\n",
            "        [0.5357],\n",
            "        [0.5496],\n",
            "        [0.5635],\n",
            "        [0.5774],\n",
            "        [0.5913],\n",
            "        [0.6052],\n",
            "        [0.6191],\n",
            "        [0.6330],\n",
            "        [0.6469],\n",
            "        [0.6608],\n",
            "        [0.6747],\n",
            "        [0.6886],\n",
            "        [0.7025],\n",
            "        [0.7164],\n",
            "        [0.7303],\n",
            "        [0.7442],\n",
            "        [0.7581],\n",
            "        [0.7720],\n",
            "        [0.7859],\n",
            "        [0.7998],\n",
            "        [0.8137],\n",
            "        [0.8276],\n",
            "        [0.8415]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3093],\n",
            "        [0.3233],\n",
            "        [0.3373],\n",
            "        [0.3513],\n",
            "        [0.3652],\n",
            "        [0.3792],\n",
            "        [0.3932],\n",
            "        [0.4072],\n",
            "        [0.4212],\n",
            "        [0.4351],\n",
            "        [0.4491],\n",
            "        [0.4631],\n",
            "        [0.4771],\n",
            "        [0.4911],\n",
            "        [0.5050],\n",
            "        [0.5190],\n",
            "        [0.5330],\n",
            "        [0.5470],\n",
            "        [0.5610],\n",
            "        [0.5749],\n",
            "        [0.5889],\n",
            "        [0.6029],\n",
            "        [0.6169],\n",
            "        [0.6309],\n",
            "        [0.6448],\n",
            "        [0.6588],\n",
            "        [0.6728],\n",
            "        [0.6868],\n",
            "        [0.7008],\n",
            "        [0.7147],\n",
            "        [0.7287],\n",
            "        [0.7427],\n",
            "        [0.7567],\n",
            "        [0.7707],\n",
            "        [0.7847],\n",
            "        [0.7986],\n",
            "        [0.8126],\n",
            "        [0.8266],\n",
            "        [0.8406],\n",
            "        [0.8546]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.2993],\n",
            "        [0.3132],\n",
            "        [0.3271],\n",
            "        [0.3410],\n",
            "        [0.3549],\n",
            "        [0.3688],\n",
            "        [0.3827],\n",
            "        [0.3966],\n",
            "        [0.4105],\n",
            "        [0.4244],\n",
            "        [0.4383],\n",
            "        [0.4522],\n",
            "        [0.4661],\n",
            "        [0.4800],\n",
            "        [0.4939],\n",
            "        [0.5078],\n",
            "        [0.5218],\n",
            "        [0.5357],\n",
            "        [0.5496],\n",
            "        [0.5635],\n",
            "        [0.5774],\n",
            "        [0.5913],\n",
            "        [0.6052],\n",
            "        [0.6191],\n",
            "        [0.6330],\n",
            "        [0.6469],\n",
            "        [0.6608],\n",
            "        [0.6747],\n",
            "        [0.6886],\n",
            "        [0.7025],\n",
            "        [0.7164],\n",
            "        [0.7303],\n",
            "        [0.7442],\n",
            "        [0.7581],\n",
            "        [0.7720],\n",
            "        [0.7859],\n",
            "        [0.7998],\n",
            "        [0.8137],\n",
            "        [0.8276],\n",
            "        [0.8415]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3093],\n",
            "        [0.3233],\n",
            "        [0.3373],\n",
            "        [0.3513],\n",
            "        [0.3652],\n",
            "        [0.3792],\n",
            "        [0.3932],\n",
            "        [0.4072],\n",
            "        [0.4212],\n",
            "        [0.4351],\n",
            "        [0.4491],\n",
            "        [0.4631],\n",
            "        [0.4771],\n",
            "        [0.4911],\n",
            "        [0.5050],\n",
            "        [0.5190],\n",
            "        [0.5330],\n",
            "        [0.5470],\n",
            "        [0.5610],\n",
            "        [0.5749],\n",
            "        [0.5889],\n",
            "        [0.6029],\n",
            "        [0.6169],\n",
            "        [0.6309],\n",
            "        [0.6448],\n",
            "        [0.6588],\n",
            "        [0.6728],\n",
            "        [0.6868],\n",
            "        [0.7008],\n",
            "        [0.7147],\n",
            "        [0.7287],\n",
            "        [0.7427],\n",
            "        [0.7567],\n",
            "        [0.7707],\n",
            "        [0.7847],\n",
            "        [0.7986],\n",
            "        [0.8126],\n",
            "        [0.8266],\n",
            "        [0.8406],\n",
            "        [0.8546]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.2993],\n",
            "        [0.3132],\n",
            "        [0.3271],\n",
            "        [0.3410],\n",
            "        [0.3549],\n",
            "        [0.3688],\n",
            "        [0.3827],\n",
            "        [0.3966],\n",
            "        [0.4105],\n",
            "        [0.4244],\n",
            "        [0.4383],\n",
            "        [0.4522],\n",
            "        [0.4661],\n",
            "        [0.4800],\n",
            "        [0.4939],\n",
            "        [0.5078],\n",
            "        [0.5218],\n",
            "        [0.5357],\n",
            "        [0.5496],\n",
            "        [0.5635],\n",
            "        [0.5774],\n",
            "        [0.5913],\n",
            "        [0.6052],\n",
            "        [0.6191],\n",
            "        [0.6330],\n",
            "        [0.6469],\n",
            "        [0.6608],\n",
            "        [0.6747],\n",
            "        [0.6886],\n",
            "        [0.7025],\n",
            "        [0.7164],\n",
            "        [0.7303],\n",
            "        [0.7442],\n",
            "        [0.7581],\n",
            "        [0.7720],\n",
            "        [0.7859],\n",
            "        [0.7998],\n",
            "        [0.8137],\n",
            "        [0.8276],\n",
            "        [0.8415]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3093],\n",
            "        [0.3233],\n",
            "        [0.3373],\n",
            "        [0.3513],\n",
            "        [0.3652],\n",
            "        [0.3792],\n",
            "        [0.3932],\n",
            "        [0.4072],\n",
            "        [0.4212],\n",
            "        [0.4351],\n",
            "        [0.4491],\n",
            "        [0.4631],\n",
            "        [0.4771],\n",
            "        [0.4911],\n",
            "        [0.5050],\n",
            "        [0.5190],\n",
            "        [0.5330],\n",
            "        [0.5470],\n",
            "        [0.5610],\n",
            "        [0.5749],\n",
            "        [0.5889],\n",
            "        [0.6029],\n",
            "        [0.6169],\n",
            "        [0.6309],\n",
            "        [0.6448],\n",
            "        [0.6588],\n",
            "        [0.6728],\n",
            "        [0.6868],\n",
            "        [0.7008],\n",
            "        [0.7147],\n",
            "        [0.7287],\n",
            "        [0.7427],\n",
            "        [0.7567],\n",
            "        [0.7707],\n",
            "        [0.7847],\n",
            "        [0.7986],\n",
            "        [0.8126],\n",
            "        [0.8266],\n",
            "        [0.8406],\n",
            "        [0.8546]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.2993],\n",
            "        [0.3132],\n",
            "        [0.3271],\n",
            "        [0.3410],\n",
            "        [0.3549],\n",
            "        [0.3688],\n",
            "        [0.3827],\n",
            "        [0.3966],\n",
            "        [0.4105],\n",
            "        [0.4244],\n",
            "        [0.4383],\n",
            "        [0.4522],\n",
            "        [0.4661],\n",
            "        [0.4800],\n",
            "        [0.4939],\n",
            "        [0.5078],\n",
            "        [0.5218],\n",
            "        [0.5357],\n",
            "        [0.5496],\n",
            "        [0.5635],\n",
            "        [0.5774],\n",
            "        [0.5913],\n",
            "        [0.6052],\n",
            "        [0.6191],\n",
            "        [0.6330],\n",
            "        [0.6469],\n",
            "        [0.6608],\n",
            "        [0.6747],\n",
            "        [0.6886],\n",
            "        [0.7025],\n",
            "        [0.7164],\n",
            "        [0.7303],\n",
            "        [0.7442],\n",
            "        [0.7581],\n",
            "        [0.7720],\n",
            "        [0.7859],\n",
            "        [0.7998],\n",
            "        [0.8137],\n",
            "        [0.8276],\n",
            "        [0.8415]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3093],\n",
            "        [0.3233],\n",
            "        [0.3373],\n",
            "        [0.3513],\n",
            "        [0.3652],\n",
            "        [0.3792],\n",
            "        [0.3932],\n",
            "        [0.4072],\n",
            "        [0.4212],\n",
            "        [0.4351],\n",
            "        [0.4491],\n",
            "        [0.4631],\n",
            "        [0.4771],\n",
            "        [0.4911],\n",
            "        [0.5050],\n",
            "        [0.5190],\n",
            "        [0.5330],\n",
            "        [0.5470],\n",
            "        [0.5610],\n",
            "        [0.5749],\n",
            "        [0.5889],\n",
            "        [0.6029],\n",
            "        [0.6169],\n",
            "        [0.6309],\n",
            "        [0.6448],\n",
            "        [0.6588],\n",
            "        [0.6728],\n",
            "        [0.6868],\n",
            "        [0.7008],\n",
            "        [0.7147],\n",
            "        [0.7287],\n",
            "        [0.7427],\n",
            "        [0.7567],\n",
            "        [0.7707],\n",
            "        [0.7847],\n",
            "        [0.7986],\n",
            "        [0.8126],\n",
            "        [0.8266],\n",
            "        [0.8406],\n",
            "        [0.8546]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.2993],\n",
            "        [0.3132],\n",
            "        [0.3271],\n",
            "        [0.3410],\n",
            "        [0.3549],\n",
            "        [0.3688],\n",
            "        [0.3827],\n",
            "        [0.3966],\n",
            "        [0.4105],\n",
            "        [0.4244],\n",
            "        [0.4383],\n",
            "        [0.4522],\n",
            "        [0.4661],\n",
            "        [0.4800],\n",
            "        [0.4939],\n",
            "        [0.5078],\n",
            "        [0.5218],\n",
            "        [0.5357],\n",
            "        [0.5496],\n",
            "        [0.5635],\n",
            "        [0.5774],\n",
            "        [0.5913],\n",
            "        [0.6052],\n",
            "        [0.6191],\n",
            "        [0.6330],\n",
            "        [0.6469],\n",
            "        [0.6608],\n",
            "        [0.6747],\n",
            "        [0.6886],\n",
            "        [0.7025],\n",
            "        [0.7164],\n",
            "        [0.7303],\n",
            "        [0.7442],\n",
            "        [0.7581],\n",
            "        [0.7720],\n",
            "        [0.7859],\n",
            "        [0.7998],\n",
            "        [0.8137],\n",
            "        [0.8276],\n",
            "        [0.8415]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3093],\n",
            "        [0.3233],\n",
            "        [0.3373],\n",
            "        [0.3513],\n",
            "        [0.3652],\n",
            "        [0.3792],\n",
            "        [0.3932],\n",
            "        [0.4072],\n",
            "        [0.4212],\n",
            "        [0.4351],\n",
            "        [0.4491],\n",
            "        [0.4631],\n",
            "        [0.4771],\n",
            "        [0.4911],\n",
            "        [0.5050],\n",
            "        [0.5190],\n",
            "        [0.5330],\n",
            "        [0.5470],\n",
            "        [0.5610],\n",
            "        [0.5749],\n",
            "        [0.5889],\n",
            "        [0.6029],\n",
            "        [0.6169],\n",
            "        [0.6309],\n",
            "        [0.6448],\n",
            "        [0.6588],\n",
            "        [0.6728],\n",
            "        [0.6868],\n",
            "        [0.7008],\n",
            "        [0.7147],\n",
            "        [0.7287],\n",
            "        [0.7427],\n",
            "        [0.7567],\n",
            "        [0.7707],\n",
            "        [0.7847],\n",
            "        [0.7986],\n",
            "        [0.8126],\n",
            "        [0.8266],\n",
            "        [0.8406],\n",
            "        [0.8546]], grad_fn=<AddBackward0>)\n",
            "Epoch: 220 | MAE Train Loss: 0.008932482451200485 | MAE Test Loss: 0.005023092031478882\n",
            "tensor([[0.2993],\n",
            "        [0.3132],\n",
            "        [0.3271],\n",
            "        [0.3410],\n",
            "        [0.3549],\n",
            "        [0.3688],\n",
            "        [0.3827],\n",
            "        [0.3966],\n",
            "        [0.4105],\n",
            "        [0.4244],\n",
            "        [0.4383],\n",
            "        [0.4522],\n",
            "        [0.4661],\n",
            "        [0.4800],\n",
            "        [0.4939],\n",
            "        [0.5078],\n",
            "        [0.5218],\n",
            "        [0.5357],\n",
            "        [0.5496],\n",
            "        [0.5635],\n",
            "        [0.5774],\n",
            "        [0.5913],\n",
            "        [0.6052],\n",
            "        [0.6191],\n",
            "        [0.6330],\n",
            "        [0.6469],\n",
            "        [0.6608],\n",
            "        [0.6747],\n",
            "        [0.6886],\n",
            "        [0.7025],\n",
            "        [0.7164],\n",
            "        [0.7303],\n",
            "        [0.7442],\n",
            "        [0.7581],\n",
            "        [0.7720],\n",
            "        [0.7859],\n",
            "        [0.7998],\n",
            "        [0.8137],\n",
            "        [0.8276],\n",
            "        [0.8415]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3093],\n",
            "        [0.3233],\n",
            "        [0.3373],\n",
            "        [0.3513],\n",
            "        [0.3652],\n",
            "        [0.3792],\n",
            "        [0.3932],\n",
            "        [0.4072],\n",
            "        [0.4212],\n",
            "        [0.4351],\n",
            "        [0.4491],\n",
            "        [0.4631],\n",
            "        [0.4771],\n",
            "        [0.4911],\n",
            "        [0.5050],\n",
            "        [0.5190],\n",
            "        [0.5330],\n",
            "        [0.5470],\n",
            "        [0.5610],\n",
            "        [0.5749],\n",
            "        [0.5889],\n",
            "        [0.6029],\n",
            "        [0.6169],\n",
            "        [0.6309],\n",
            "        [0.6448],\n",
            "        [0.6588],\n",
            "        [0.6728],\n",
            "        [0.6868],\n",
            "        [0.7008],\n",
            "        [0.7147],\n",
            "        [0.7287],\n",
            "        [0.7427],\n",
            "        [0.7567],\n",
            "        [0.7707],\n",
            "        [0.7847],\n",
            "        [0.7986],\n",
            "        [0.8126],\n",
            "        [0.8266],\n",
            "        [0.8406],\n",
            "        [0.8546]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.2993],\n",
            "        [0.3132],\n",
            "        [0.3271],\n",
            "        [0.3410],\n",
            "        [0.3549],\n",
            "        [0.3688],\n",
            "        [0.3827],\n",
            "        [0.3966],\n",
            "        [0.4105],\n",
            "        [0.4244],\n",
            "        [0.4383],\n",
            "        [0.4522],\n",
            "        [0.4661],\n",
            "        [0.4800],\n",
            "        [0.4939],\n",
            "        [0.5078],\n",
            "        [0.5218],\n",
            "        [0.5357],\n",
            "        [0.5496],\n",
            "        [0.5635],\n",
            "        [0.5774],\n",
            "        [0.5913],\n",
            "        [0.6052],\n",
            "        [0.6191],\n",
            "        [0.6330],\n",
            "        [0.6469],\n",
            "        [0.6608],\n",
            "        [0.6747],\n",
            "        [0.6886],\n",
            "        [0.7025],\n",
            "        [0.7164],\n",
            "        [0.7303],\n",
            "        [0.7442],\n",
            "        [0.7581],\n",
            "        [0.7720],\n",
            "        [0.7859],\n",
            "        [0.7998],\n",
            "        [0.8137],\n",
            "        [0.8276],\n",
            "        [0.8415]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3093],\n",
            "        [0.3233],\n",
            "        [0.3373],\n",
            "        [0.3513],\n",
            "        [0.3652],\n",
            "        [0.3792],\n",
            "        [0.3932],\n",
            "        [0.4072],\n",
            "        [0.4212],\n",
            "        [0.4351],\n",
            "        [0.4491],\n",
            "        [0.4631],\n",
            "        [0.4771],\n",
            "        [0.4911],\n",
            "        [0.5050],\n",
            "        [0.5190],\n",
            "        [0.5330],\n",
            "        [0.5470],\n",
            "        [0.5610],\n",
            "        [0.5749],\n",
            "        [0.5889],\n",
            "        [0.6029],\n",
            "        [0.6169],\n",
            "        [0.6309],\n",
            "        [0.6448],\n",
            "        [0.6588],\n",
            "        [0.6728],\n",
            "        [0.6868],\n",
            "        [0.7008],\n",
            "        [0.7147],\n",
            "        [0.7287],\n",
            "        [0.7427],\n",
            "        [0.7567],\n",
            "        [0.7707],\n",
            "        [0.7847],\n",
            "        [0.7986],\n",
            "        [0.8126],\n",
            "        [0.8266],\n",
            "        [0.8406],\n",
            "        [0.8546]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.2993],\n",
            "        [0.3132],\n",
            "        [0.3271],\n",
            "        [0.3410],\n",
            "        [0.3549],\n",
            "        [0.3688],\n",
            "        [0.3827],\n",
            "        [0.3966],\n",
            "        [0.4105],\n",
            "        [0.4244],\n",
            "        [0.4383],\n",
            "        [0.4522],\n",
            "        [0.4661],\n",
            "        [0.4800],\n",
            "        [0.4939],\n",
            "        [0.5078],\n",
            "        [0.5218],\n",
            "        [0.5357],\n",
            "        [0.5496],\n",
            "        [0.5635],\n",
            "        [0.5774],\n",
            "        [0.5913],\n",
            "        [0.6052],\n",
            "        [0.6191],\n",
            "        [0.6330],\n",
            "        [0.6469],\n",
            "        [0.6608],\n",
            "        [0.6747],\n",
            "        [0.6886],\n",
            "        [0.7025],\n",
            "        [0.7164],\n",
            "        [0.7303],\n",
            "        [0.7442],\n",
            "        [0.7581],\n",
            "        [0.7720],\n",
            "        [0.7859],\n",
            "        [0.7998],\n",
            "        [0.8137],\n",
            "        [0.8276],\n",
            "        [0.8415]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3093],\n",
            "        [0.3233],\n",
            "        [0.3373],\n",
            "        [0.3513],\n",
            "        [0.3652],\n",
            "        [0.3792],\n",
            "        [0.3932],\n",
            "        [0.4072],\n",
            "        [0.4212],\n",
            "        [0.4351],\n",
            "        [0.4491],\n",
            "        [0.4631],\n",
            "        [0.4771],\n",
            "        [0.4911],\n",
            "        [0.5050],\n",
            "        [0.5190],\n",
            "        [0.5330],\n",
            "        [0.5470],\n",
            "        [0.5610],\n",
            "        [0.5749],\n",
            "        [0.5889],\n",
            "        [0.6029],\n",
            "        [0.6169],\n",
            "        [0.6309],\n",
            "        [0.6448],\n",
            "        [0.6588],\n",
            "        [0.6728],\n",
            "        [0.6868],\n",
            "        [0.7008],\n",
            "        [0.7147],\n",
            "        [0.7287],\n",
            "        [0.7427],\n",
            "        [0.7567],\n",
            "        [0.7707],\n",
            "        [0.7847],\n",
            "        [0.7986],\n",
            "        [0.8126],\n",
            "        [0.8266],\n",
            "        [0.8406],\n",
            "        [0.8546]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.2993],\n",
            "        [0.3132],\n",
            "        [0.3271],\n",
            "        [0.3410],\n",
            "        [0.3549],\n",
            "        [0.3688],\n",
            "        [0.3827],\n",
            "        [0.3966],\n",
            "        [0.4105],\n",
            "        [0.4244],\n",
            "        [0.4383],\n",
            "        [0.4522],\n",
            "        [0.4661],\n",
            "        [0.4800],\n",
            "        [0.4939],\n",
            "        [0.5078],\n",
            "        [0.5218],\n",
            "        [0.5357],\n",
            "        [0.5496],\n",
            "        [0.5635],\n",
            "        [0.5774],\n",
            "        [0.5913],\n",
            "        [0.6052],\n",
            "        [0.6191],\n",
            "        [0.6330],\n",
            "        [0.6469],\n",
            "        [0.6608],\n",
            "        [0.6747],\n",
            "        [0.6886],\n",
            "        [0.7025],\n",
            "        [0.7164],\n",
            "        [0.7303],\n",
            "        [0.7442],\n",
            "        [0.7581],\n",
            "        [0.7720],\n",
            "        [0.7859],\n",
            "        [0.7998],\n",
            "        [0.8137],\n",
            "        [0.8276],\n",
            "        [0.8415]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3093],\n",
            "        [0.3233],\n",
            "        [0.3373],\n",
            "        [0.3513],\n",
            "        [0.3652],\n",
            "        [0.3792],\n",
            "        [0.3932],\n",
            "        [0.4072],\n",
            "        [0.4212],\n",
            "        [0.4351],\n",
            "        [0.4491],\n",
            "        [0.4631],\n",
            "        [0.4771],\n",
            "        [0.4911],\n",
            "        [0.5050],\n",
            "        [0.5190],\n",
            "        [0.5330],\n",
            "        [0.5470],\n",
            "        [0.5610],\n",
            "        [0.5749],\n",
            "        [0.5889],\n",
            "        [0.6029],\n",
            "        [0.6169],\n",
            "        [0.6309],\n",
            "        [0.6448],\n",
            "        [0.6588],\n",
            "        [0.6728],\n",
            "        [0.6868],\n",
            "        [0.7008],\n",
            "        [0.7147],\n",
            "        [0.7287],\n",
            "        [0.7427],\n",
            "        [0.7567],\n",
            "        [0.7707],\n",
            "        [0.7847],\n",
            "        [0.7986],\n",
            "        [0.8126],\n",
            "        [0.8266],\n",
            "        [0.8406],\n",
            "        [0.8546]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.2993],\n",
            "        [0.3132],\n",
            "        [0.3271],\n",
            "        [0.3410],\n",
            "        [0.3549],\n",
            "        [0.3688],\n",
            "        [0.3827],\n",
            "        [0.3966],\n",
            "        [0.4105],\n",
            "        [0.4244],\n",
            "        [0.4383],\n",
            "        [0.4522],\n",
            "        [0.4661],\n",
            "        [0.4800],\n",
            "        [0.4939],\n",
            "        [0.5078],\n",
            "        [0.5218],\n",
            "        [0.5357],\n",
            "        [0.5496],\n",
            "        [0.5635],\n",
            "        [0.5774],\n",
            "        [0.5913],\n",
            "        [0.6052],\n",
            "        [0.6191],\n",
            "        [0.6330],\n",
            "        [0.6469],\n",
            "        [0.6608],\n",
            "        [0.6747],\n",
            "        [0.6886],\n",
            "        [0.7025],\n",
            "        [0.7164],\n",
            "        [0.7303],\n",
            "        [0.7442],\n",
            "        [0.7581],\n",
            "        [0.7720],\n",
            "        [0.7859],\n",
            "        [0.7998],\n",
            "        [0.8137],\n",
            "        [0.8276],\n",
            "        [0.8415]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3093],\n",
            "        [0.3233],\n",
            "        [0.3373],\n",
            "        [0.3513],\n",
            "        [0.3652],\n",
            "        [0.3792],\n",
            "        [0.3932],\n",
            "        [0.4072],\n",
            "        [0.4212],\n",
            "        [0.4351],\n",
            "        [0.4491],\n",
            "        [0.4631],\n",
            "        [0.4771],\n",
            "        [0.4911],\n",
            "        [0.5050],\n",
            "        [0.5190],\n",
            "        [0.5330],\n",
            "        [0.5470],\n",
            "        [0.5610],\n",
            "        [0.5749],\n",
            "        [0.5889],\n",
            "        [0.6029],\n",
            "        [0.6169],\n",
            "        [0.6309],\n",
            "        [0.6448],\n",
            "        [0.6588],\n",
            "        [0.6728],\n",
            "        [0.6868],\n",
            "        [0.7008],\n",
            "        [0.7147],\n",
            "        [0.7287],\n",
            "        [0.7427],\n",
            "        [0.7567],\n",
            "        [0.7707],\n",
            "        [0.7847],\n",
            "        [0.7986],\n",
            "        [0.8126],\n",
            "        [0.8266],\n",
            "        [0.8406],\n",
            "        [0.8546]], grad_fn=<AddBackward0>)\n",
            "Epoch: 230 | MAE Train Loss: 0.008932482451200485 | MAE Test Loss: 0.005023092031478882\n",
            "tensor([[0.2993],\n",
            "        [0.3132],\n",
            "        [0.3271],\n",
            "        [0.3410],\n",
            "        [0.3549],\n",
            "        [0.3688],\n",
            "        [0.3827],\n",
            "        [0.3966],\n",
            "        [0.4105],\n",
            "        [0.4244],\n",
            "        [0.4383],\n",
            "        [0.4522],\n",
            "        [0.4661],\n",
            "        [0.4800],\n",
            "        [0.4939],\n",
            "        [0.5078],\n",
            "        [0.5218],\n",
            "        [0.5357],\n",
            "        [0.5496],\n",
            "        [0.5635],\n",
            "        [0.5774],\n",
            "        [0.5913],\n",
            "        [0.6052],\n",
            "        [0.6191],\n",
            "        [0.6330],\n",
            "        [0.6469],\n",
            "        [0.6608],\n",
            "        [0.6747],\n",
            "        [0.6886],\n",
            "        [0.7025],\n",
            "        [0.7164],\n",
            "        [0.7303],\n",
            "        [0.7442],\n",
            "        [0.7581],\n",
            "        [0.7720],\n",
            "        [0.7859],\n",
            "        [0.7998],\n",
            "        [0.8137],\n",
            "        [0.8276],\n",
            "        [0.8415]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3093],\n",
            "        [0.3233],\n",
            "        [0.3373],\n",
            "        [0.3513],\n",
            "        [0.3652],\n",
            "        [0.3792],\n",
            "        [0.3932],\n",
            "        [0.4072],\n",
            "        [0.4212],\n",
            "        [0.4351],\n",
            "        [0.4491],\n",
            "        [0.4631],\n",
            "        [0.4771],\n",
            "        [0.4911],\n",
            "        [0.5050],\n",
            "        [0.5190],\n",
            "        [0.5330],\n",
            "        [0.5470],\n",
            "        [0.5610],\n",
            "        [0.5749],\n",
            "        [0.5889],\n",
            "        [0.6029],\n",
            "        [0.6169],\n",
            "        [0.6309],\n",
            "        [0.6448],\n",
            "        [0.6588],\n",
            "        [0.6728],\n",
            "        [0.6868],\n",
            "        [0.7008],\n",
            "        [0.7147],\n",
            "        [0.7287],\n",
            "        [0.7427],\n",
            "        [0.7567],\n",
            "        [0.7707],\n",
            "        [0.7847],\n",
            "        [0.7986],\n",
            "        [0.8126],\n",
            "        [0.8266],\n",
            "        [0.8406],\n",
            "        [0.8546]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.2993],\n",
            "        [0.3132],\n",
            "        [0.3271],\n",
            "        [0.3410],\n",
            "        [0.3549],\n",
            "        [0.3688],\n",
            "        [0.3827],\n",
            "        [0.3966],\n",
            "        [0.4105],\n",
            "        [0.4244],\n",
            "        [0.4383],\n",
            "        [0.4522],\n",
            "        [0.4661],\n",
            "        [0.4800],\n",
            "        [0.4939],\n",
            "        [0.5078],\n",
            "        [0.5218],\n",
            "        [0.5357],\n",
            "        [0.5496],\n",
            "        [0.5635],\n",
            "        [0.5774],\n",
            "        [0.5913],\n",
            "        [0.6052],\n",
            "        [0.6191],\n",
            "        [0.6330],\n",
            "        [0.6469],\n",
            "        [0.6608],\n",
            "        [0.6747],\n",
            "        [0.6886],\n",
            "        [0.7025],\n",
            "        [0.7164],\n",
            "        [0.7303],\n",
            "        [0.7442],\n",
            "        [0.7581],\n",
            "        [0.7720],\n",
            "        [0.7859],\n",
            "        [0.7998],\n",
            "        [0.8137],\n",
            "        [0.8276],\n",
            "        [0.8415]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3093],\n",
            "        [0.3233],\n",
            "        [0.3373],\n",
            "        [0.3513],\n",
            "        [0.3652],\n",
            "        [0.3792],\n",
            "        [0.3932],\n",
            "        [0.4072],\n",
            "        [0.4212],\n",
            "        [0.4351],\n",
            "        [0.4491],\n",
            "        [0.4631],\n",
            "        [0.4771],\n",
            "        [0.4911],\n",
            "        [0.5050],\n",
            "        [0.5190],\n",
            "        [0.5330],\n",
            "        [0.5470],\n",
            "        [0.5610],\n",
            "        [0.5749],\n",
            "        [0.5889],\n",
            "        [0.6029],\n",
            "        [0.6169],\n",
            "        [0.6309],\n",
            "        [0.6448],\n",
            "        [0.6588],\n",
            "        [0.6728],\n",
            "        [0.6868],\n",
            "        [0.7008],\n",
            "        [0.7147],\n",
            "        [0.7287],\n",
            "        [0.7427],\n",
            "        [0.7567],\n",
            "        [0.7707],\n",
            "        [0.7847],\n",
            "        [0.7986],\n",
            "        [0.8126],\n",
            "        [0.8266],\n",
            "        [0.8406],\n",
            "        [0.8546]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.2993],\n",
            "        [0.3132],\n",
            "        [0.3271],\n",
            "        [0.3410],\n",
            "        [0.3549],\n",
            "        [0.3688],\n",
            "        [0.3827],\n",
            "        [0.3966],\n",
            "        [0.4105],\n",
            "        [0.4244],\n",
            "        [0.4383],\n",
            "        [0.4522],\n",
            "        [0.4661],\n",
            "        [0.4800],\n",
            "        [0.4939],\n",
            "        [0.5078],\n",
            "        [0.5218],\n",
            "        [0.5357],\n",
            "        [0.5496],\n",
            "        [0.5635],\n",
            "        [0.5774],\n",
            "        [0.5913],\n",
            "        [0.6052],\n",
            "        [0.6191],\n",
            "        [0.6330],\n",
            "        [0.6469],\n",
            "        [0.6608],\n",
            "        [0.6747],\n",
            "        [0.6886],\n",
            "        [0.7025],\n",
            "        [0.7164],\n",
            "        [0.7303],\n",
            "        [0.7442],\n",
            "        [0.7581],\n",
            "        [0.7720],\n",
            "        [0.7859],\n",
            "        [0.7998],\n",
            "        [0.8137],\n",
            "        [0.8276],\n",
            "        [0.8415]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3093],\n",
            "        [0.3233],\n",
            "        [0.3373],\n",
            "        [0.3513],\n",
            "        [0.3652],\n",
            "        [0.3792],\n",
            "        [0.3932],\n",
            "        [0.4072],\n",
            "        [0.4212],\n",
            "        [0.4351],\n",
            "        [0.4491],\n",
            "        [0.4631],\n",
            "        [0.4771],\n",
            "        [0.4911],\n",
            "        [0.5050],\n",
            "        [0.5190],\n",
            "        [0.5330],\n",
            "        [0.5470],\n",
            "        [0.5610],\n",
            "        [0.5749],\n",
            "        [0.5889],\n",
            "        [0.6029],\n",
            "        [0.6169],\n",
            "        [0.6309],\n",
            "        [0.6448],\n",
            "        [0.6588],\n",
            "        [0.6728],\n",
            "        [0.6868],\n",
            "        [0.7008],\n",
            "        [0.7147],\n",
            "        [0.7287],\n",
            "        [0.7427],\n",
            "        [0.7567],\n",
            "        [0.7707],\n",
            "        [0.7847],\n",
            "        [0.7986],\n",
            "        [0.8126],\n",
            "        [0.8266],\n",
            "        [0.8406],\n",
            "        [0.8546]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.2993],\n",
            "        [0.3132],\n",
            "        [0.3271],\n",
            "        [0.3410],\n",
            "        [0.3549],\n",
            "        [0.3688],\n",
            "        [0.3827],\n",
            "        [0.3966],\n",
            "        [0.4105],\n",
            "        [0.4244],\n",
            "        [0.4383],\n",
            "        [0.4522],\n",
            "        [0.4661],\n",
            "        [0.4800],\n",
            "        [0.4939],\n",
            "        [0.5078],\n",
            "        [0.5218],\n",
            "        [0.5357],\n",
            "        [0.5496],\n",
            "        [0.5635],\n",
            "        [0.5774],\n",
            "        [0.5913],\n",
            "        [0.6052],\n",
            "        [0.6191],\n",
            "        [0.6330],\n",
            "        [0.6469],\n",
            "        [0.6608],\n",
            "        [0.6747],\n",
            "        [0.6886],\n",
            "        [0.7025],\n",
            "        [0.7164],\n",
            "        [0.7303],\n",
            "        [0.7442],\n",
            "        [0.7581],\n",
            "        [0.7720],\n",
            "        [0.7859],\n",
            "        [0.7998],\n",
            "        [0.8137],\n",
            "        [0.8276],\n",
            "        [0.8415]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3093],\n",
            "        [0.3233],\n",
            "        [0.3373],\n",
            "        [0.3513],\n",
            "        [0.3652],\n",
            "        [0.3792],\n",
            "        [0.3932],\n",
            "        [0.4072],\n",
            "        [0.4212],\n",
            "        [0.4351],\n",
            "        [0.4491],\n",
            "        [0.4631],\n",
            "        [0.4771],\n",
            "        [0.4911],\n",
            "        [0.5050],\n",
            "        [0.5190],\n",
            "        [0.5330],\n",
            "        [0.5470],\n",
            "        [0.5610],\n",
            "        [0.5749],\n",
            "        [0.5889],\n",
            "        [0.6029],\n",
            "        [0.6169],\n",
            "        [0.6309],\n",
            "        [0.6448],\n",
            "        [0.6588],\n",
            "        [0.6728],\n",
            "        [0.6868],\n",
            "        [0.7008],\n",
            "        [0.7147],\n",
            "        [0.7287],\n",
            "        [0.7427],\n",
            "        [0.7567],\n",
            "        [0.7707],\n",
            "        [0.7847],\n",
            "        [0.7986],\n",
            "        [0.8126],\n",
            "        [0.8266],\n",
            "        [0.8406],\n",
            "        [0.8546]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.2993],\n",
            "        [0.3132],\n",
            "        [0.3271],\n",
            "        [0.3410],\n",
            "        [0.3549],\n",
            "        [0.3688],\n",
            "        [0.3827],\n",
            "        [0.3966],\n",
            "        [0.4105],\n",
            "        [0.4244],\n",
            "        [0.4383],\n",
            "        [0.4522],\n",
            "        [0.4661],\n",
            "        [0.4800],\n",
            "        [0.4939],\n",
            "        [0.5078],\n",
            "        [0.5218],\n",
            "        [0.5357],\n",
            "        [0.5496],\n",
            "        [0.5635],\n",
            "        [0.5774],\n",
            "        [0.5913],\n",
            "        [0.6052],\n",
            "        [0.6191],\n",
            "        [0.6330],\n",
            "        [0.6469],\n",
            "        [0.6608],\n",
            "        [0.6747],\n",
            "        [0.6886],\n",
            "        [0.7025],\n",
            "        [0.7164],\n",
            "        [0.7303],\n",
            "        [0.7442],\n",
            "        [0.7581],\n",
            "        [0.7720],\n",
            "        [0.7859],\n",
            "        [0.7998],\n",
            "        [0.8137],\n",
            "        [0.8276],\n",
            "        [0.8415]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3093],\n",
            "        [0.3233],\n",
            "        [0.3373],\n",
            "        [0.3513],\n",
            "        [0.3652],\n",
            "        [0.3792],\n",
            "        [0.3932],\n",
            "        [0.4072],\n",
            "        [0.4212],\n",
            "        [0.4351],\n",
            "        [0.4491],\n",
            "        [0.4631],\n",
            "        [0.4771],\n",
            "        [0.4911],\n",
            "        [0.5050],\n",
            "        [0.5190],\n",
            "        [0.5330],\n",
            "        [0.5470],\n",
            "        [0.5610],\n",
            "        [0.5749],\n",
            "        [0.5889],\n",
            "        [0.6029],\n",
            "        [0.6169],\n",
            "        [0.6309],\n",
            "        [0.6448],\n",
            "        [0.6588],\n",
            "        [0.6728],\n",
            "        [0.6868],\n",
            "        [0.7008],\n",
            "        [0.7147],\n",
            "        [0.7287],\n",
            "        [0.7427],\n",
            "        [0.7567],\n",
            "        [0.7707],\n",
            "        [0.7847],\n",
            "        [0.7986],\n",
            "        [0.8126],\n",
            "        [0.8266],\n",
            "        [0.8406],\n",
            "        [0.8546]], grad_fn=<AddBackward0>)\n",
            "Epoch: 240 | MAE Train Loss: 0.008932482451200485 | MAE Test Loss: 0.005023092031478882\n",
            "tensor([[0.2993],\n",
            "        [0.3132],\n",
            "        [0.3271],\n",
            "        [0.3410],\n",
            "        [0.3549],\n",
            "        [0.3688],\n",
            "        [0.3827],\n",
            "        [0.3966],\n",
            "        [0.4105],\n",
            "        [0.4244],\n",
            "        [0.4383],\n",
            "        [0.4522],\n",
            "        [0.4661],\n",
            "        [0.4800],\n",
            "        [0.4939],\n",
            "        [0.5078],\n",
            "        [0.5218],\n",
            "        [0.5357],\n",
            "        [0.5496],\n",
            "        [0.5635],\n",
            "        [0.5774],\n",
            "        [0.5913],\n",
            "        [0.6052],\n",
            "        [0.6191],\n",
            "        [0.6330],\n",
            "        [0.6469],\n",
            "        [0.6608],\n",
            "        [0.6747],\n",
            "        [0.6886],\n",
            "        [0.7025],\n",
            "        [0.7164],\n",
            "        [0.7303],\n",
            "        [0.7442],\n",
            "        [0.7581],\n",
            "        [0.7720],\n",
            "        [0.7859],\n",
            "        [0.7998],\n",
            "        [0.8137],\n",
            "        [0.8276],\n",
            "        [0.8415]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3093],\n",
            "        [0.3233],\n",
            "        [0.3373],\n",
            "        [0.3513],\n",
            "        [0.3652],\n",
            "        [0.3792],\n",
            "        [0.3932],\n",
            "        [0.4072],\n",
            "        [0.4212],\n",
            "        [0.4351],\n",
            "        [0.4491],\n",
            "        [0.4631],\n",
            "        [0.4771],\n",
            "        [0.4911],\n",
            "        [0.5050],\n",
            "        [0.5190],\n",
            "        [0.5330],\n",
            "        [0.5470],\n",
            "        [0.5610],\n",
            "        [0.5749],\n",
            "        [0.5889],\n",
            "        [0.6029],\n",
            "        [0.6169],\n",
            "        [0.6309],\n",
            "        [0.6448],\n",
            "        [0.6588],\n",
            "        [0.6728],\n",
            "        [0.6868],\n",
            "        [0.7008],\n",
            "        [0.7147],\n",
            "        [0.7287],\n",
            "        [0.7427],\n",
            "        [0.7567],\n",
            "        [0.7707],\n",
            "        [0.7847],\n",
            "        [0.7986],\n",
            "        [0.8126],\n",
            "        [0.8266],\n",
            "        [0.8406],\n",
            "        [0.8546]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.2993],\n",
            "        [0.3132],\n",
            "        [0.3271],\n",
            "        [0.3410],\n",
            "        [0.3549],\n",
            "        [0.3688],\n",
            "        [0.3827],\n",
            "        [0.3966],\n",
            "        [0.4105],\n",
            "        [0.4244],\n",
            "        [0.4383],\n",
            "        [0.4522],\n",
            "        [0.4661],\n",
            "        [0.4800],\n",
            "        [0.4939],\n",
            "        [0.5078],\n",
            "        [0.5218],\n",
            "        [0.5357],\n",
            "        [0.5496],\n",
            "        [0.5635],\n",
            "        [0.5774],\n",
            "        [0.5913],\n",
            "        [0.6052],\n",
            "        [0.6191],\n",
            "        [0.6330],\n",
            "        [0.6469],\n",
            "        [0.6608],\n",
            "        [0.6747],\n",
            "        [0.6886],\n",
            "        [0.7025],\n",
            "        [0.7164],\n",
            "        [0.7303],\n",
            "        [0.7442],\n",
            "        [0.7581],\n",
            "        [0.7720],\n",
            "        [0.7859],\n",
            "        [0.7998],\n",
            "        [0.8137],\n",
            "        [0.8276],\n",
            "        [0.8415]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3093],\n",
            "        [0.3233],\n",
            "        [0.3373],\n",
            "        [0.3513],\n",
            "        [0.3652],\n",
            "        [0.3792],\n",
            "        [0.3932],\n",
            "        [0.4072],\n",
            "        [0.4212],\n",
            "        [0.4351],\n",
            "        [0.4491],\n",
            "        [0.4631],\n",
            "        [0.4771],\n",
            "        [0.4911],\n",
            "        [0.5050],\n",
            "        [0.5190],\n",
            "        [0.5330],\n",
            "        [0.5470],\n",
            "        [0.5610],\n",
            "        [0.5749],\n",
            "        [0.5889],\n",
            "        [0.6029],\n",
            "        [0.6169],\n",
            "        [0.6309],\n",
            "        [0.6448],\n",
            "        [0.6588],\n",
            "        [0.6728],\n",
            "        [0.6868],\n",
            "        [0.7008],\n",
            "        [0.7147],\n",
            "        [0.7287],\n",
            "        [0.7427],\n",
            "        [0.7567],\n",
            "        [0.7707],\n",
            "        [0.7847],\n",
            "        [0.7986],\n",
            "        [0.8126],\n",
            "        [0.8266],\n",
            "        [0.8406],\n",
            "        [0.8546]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.2993],\n",
            "        [0.3132],\n",
            "        [0.3271],\n",
            "        [0.3410],\n",
            "        [0.3549],\n",
            "        [0.3688],\n",
            "        [0.3827],\n",
            "        [0.3966],\n",
            "        [0.4105],\n",
            "        [0.4244],\n",
            "        [0.4383],\n",
            "        [0.4522],\n",
            "        [0.4661],\n",
            "        [0.4800],\n",
            "        [0.4939],\n",
            "        [0.5078],\n",
            "        [0.5218],\n",
            "        [0.5357],\n",
            "        [0.5496],\n",
            "        [0.5635],\n",
            "        [0.5774],\n",
            "        [0.5913],\n",
            "        [0.6052],\n",
            "        [0.6191],\n",
            "        [0.6330],\n",
            "        [0.6469],\n",
            "        [0.6608],\n",
            "        [0.6747],\n",
            "        [0.6886],\n",
            "        [0.7025],\n",
            "        [0.7164],\n",
            "        [0.7303],\n",
            "        [0.7442],\n",
            "        [0.7581],\n",
            "        [0.7720],\n",
            "        [0.7859],\n",
            "        [0.7998],\n",
            "        [0.8137],\n",
            "        [0.8276],\n",
            "        [0.8415]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3093],\n",
            "        [0.3233],\n",
            "        [0.3373],\n",
            "        [0.3513],\n",
            "        [0.3652],\n",
            "        [0.3792],\n",
            "        [0.3932],\n",
            "        [0.4072],\n",
            "        [0.4212],\n",
            "        [0.4351],\n",
            "        [0.4491],\n",
            "        [0.4631],\n",
            "        [0.4771],\n",
            "        [0.4911],\n",
            "        [0.5050],\n",
            "        [0.5190],\n",
            "        [0.5330],\n",
            "        [0.5470],\n",
            "        [0.5610],\n",
            "        [0.5749],\n",
            "        [0.5889],\n",
            "        [0.6029],\n",
            "        [0.6169],\n",
            "        [0.6309],\n",
            "        [0.6448],\n",
            "        [0.6588],\n",
            "        [0.6728],\n",
            "        [0.6868],\n",
            "        [0.7008],\n",
            "        [0.7147],\n",
            "        [0.7287],\n",
            "        [0.7427],\n",
            "        [0.7567],\n",
            "        [0.7707],\n",
            "        [0.7847],\n",
            "        [0.7986],\n",
            "        [0.8126],\n",
            "        [0.8266],\n",
            "        [0.8406],\n",
            "        [0.8546]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.2993],\n",
            "        [0.3132],\n",
            "        [0.3271],\n",
            "        [0.3410],\n",
            "        [0.3549],\n",
            "        [0.3688],\n",
            "        [0.3827],\n",
            "        [0.3966],\n",
            "        [0.4105],\n",
            "        [0.4244],\n",
            "        [0.4383],\n",
            "        [0.4522],\n",
            "        [0.4661],\n",
            "        [0.4800],\n",
            "        [0.4939],\n",
            "        [0.5078],\n",
            "        [0.5218],\n",
            "        [0.5357],\n",
            "        [0.5496],\n",
            "        [0.5635],\n",
            "        [0.5774],\n",
            "        [0.5913],\n",
            "        [0.6052],\n",
            "        [0.6191],\n",
            "        [0.6330],\n",
            "        [0.6469],\n",
            "        [0.6608],\n",
            "        [0.6747],\n",
            "        [0.6886],\n",
            "        [0.7025],\n",
            "        [0.7164],\n",
            "        [0.7303],\n",
            "        [0.7442],\n",
            "        [0.7581],\n",
            "        [0.7720],\n",
            "        [0.7859],\n",
            "        [0.7998],\n",
            "        [0.8137],\n",
            "        [0.8276],\n",
            "        [0.8415]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3093],\n",
            "        [0.3233],\n",
            "        [0.3373],\n",
            "        [0.3513],\n",
            "        [0.3652],\n",
            "        [0.3792],\n",
            "        [0.3932],\n",
            "        [0.4072],\n",
            "        [0.4212],\n",
            "        [0.4351],\n",
            "        [0.4491],\n",
            "        [0.4631],\n",
            "        [0.4771],\n",
            "        [0.4911],\n",
            "        [0.5050],\n",
            "        [0.5190],\n",
            "        [0.5330],\n",
            "        [0.5470],\n",
            "        [0.5610],\n",
            "        [0.5749],\n",
            "        [0.5889],\n",
            "        [0.6029],\n",
            "        [0.6169],\n",
            "        [0.6309],\n",
            "        [0.6448],\n",
            "        [0.6588],\n",
            "        [0.6728],\n",
            "        [0.6868],\n",
            "        [0.7008],\n",
            "        [0.7147],\n",
            "        [0.7287],\n",
            "        [0.7427],\n",
            "        [0.7567],\n",
            "        [0.7707],\n",
            "        [0.7847],\n",
            "        [0.7986],\n",
            "        [0.8126],\n",
            "        [0.8266],\n",
            "        [0.8406],\n",
            "        [0.8546]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.2993],\n",
            "        [0.3132],\n",
            "        [0.3271],\n",
            "        [0.3410],\n",
            "        [0.3549],\n",
            "        [0.3688],\n",
            "        [0.3827],\n",
            "        [0.3966],\n",
            "        [0.4105],\n",
            "        [0.4244],\n",
            "        [0.4383],\n",
            "        [0.4522],\n",
            "        [0.4661],\n",
            "        [0.4800],\n",
            "        [0.4939],\n",
            "        [0.5078],\n",
            "        [0.5218],\n",
            "        [0.5357],\n",
            "        [0.5496],\n",
            "        [0.5635],\n",
            "        [0.5774],\n",
            "        [0.5913],\n",
            "        [0.6052],\n",
            "        [0.6191],\n",
            "        [0.6330],\n",
            "        [0.6469],\n",
            "        [0.6608],\n",
            "        [0.6747],\n",
            "        [0.6886],\n",
            "        [0.7025],\n",
            "        [0.7164],\n",
            "        [0.7303],\n",
            "        [0.7442],\n",
            "        [0.7581],\n",
            "        [0.7720],\n",
            "        [0.7859],\n",
            "        [0.7998],\n",
            "        [0.8137],\n",
            "        [0.8276],\n",
            "        [0.8415]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3093],\n",
            "        [0.3233],\n",
            "        [0.3373],\n",
            "        [0.3513],\n",
            "        [0.3652],\n",
            "        [0.3792],\n",
            "        [0.3932],\n",
            "        [0.4072],\n",
            "        [0.4212],\n",
            "        [0.4351],\n",
            "        [0.4491],\n",
            "        [0.4631],\n",
            "        [0.4771],\n",
            "        [0.4911],\n",
            "        [0.5050],\n",
            "        [0.5190],\n",
            "        [0.5330],\n",
            "        [0.5470],\n",
            "        [0.5610],\n",
            "        [0.5749],\n",
            "        [0.5889],\n",
            "        [0.6029],\n",
            "        [0.6169],\n",
            "        [0.6309],\n",
            "        [0.6448],\n",
            "        [0.6588],\n",
            "        [0.6728],\n",
            "        [0.6868],\n",
            "        [0.7008],\n",
            "        [0.7147],\n",
            "        [0.7287],\n",
            "        [0.7427],\n",
            "        [0.7567],\n",
            "        [0.7707],\n",
            "        [0.7847],\n",
            "        [0.7986],\n",
            "        [0.8126],\n",
            "        [0.8266],\n",
            "        [0.8406],\n",
            "        [0.8546]], grad_fn=<AddBackward0>)\n",
            "Epoch: 250 | MAE Train Loss: 0.008932482451200485 | MAE Test Loss: 0.005023092031478882\n",
            "tensor([[0.2993],\n",
            "        [0.3132],\n",
            "        [0.3271],\n",
            "        [0.3410],\n",
            "        [0.3549],\n",
            "        [0.3688],\n",
            "        [0.3827],\n",
            "        [0.3966],\n",
            "        [0.4105],\n",
            "        [0.4244],\n",
            "        [0.4383],\n",
            "        [0.4522],\n",
            "        [0.4661],\n",
            "        [0.4800],\n",
            "        [0.4939],\n",
            "        [0.5078],\n",
            "        [0.5218],\n",
            "        [0.5357],\n",
            "        [0.5496],\n",
            "        [0.5635],\n",
            "        [0.5774],\n",
            "        [0.5913],\n",
            "        [0.6052],\n",
            "        [0.6191],\n",
            "        [0.6330],\n",
            "        [0.6469],\n",
            "        [0.6608],\n",
            "        [0.6747],\n",
            "        [0.6886],\n",
            "        [0.7025],\n",
            "        [0.7164],\n",
            "        [0.7303],\n",
            "        [0.7442],\n",
            "        [0.7581],\n",
            "        [0.7720],\n",
            "        [0.7859],\n",
            "        [0.7998],\n",
            "        [0.8137],\n",
            "        [0.8276],\n",
            "        [0.8415]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3093],\n",
            "        [0.3233],\n",
            "        [0.3373],\n",
            "        [0.3513],\n",
            "        [0.3652],\n",
            "        [0.3792],\n",
            "        [0.3932],\n",
            "        [0.4072],\n",
            "        [0.4212],\n",
            "        [0.4351],\n",
            "        [0.4491],\n",
            "        [0.4631],\n",
            "        [0.4771],\n",
            "        [0.4911],\n",
            "        [0.5050],\n",
            "        [0.5190],\n",
            "        [0.5330],\n",
            "        [0.5470],\n",
            "        [0.5610],\n",
            "        [0.5749],\n",
            "        [0.5889],\n",
            "        [0.6029],\n",
            "        [0.6169],\n",
            "        [0.6309],\n",
            "        [0.6448],\n",
            "        [0.6588],\n",
            "        [0.6728],\n",
            "        [0.6868],\n",
            "        [0.7008],\n",
            "        [0.7147],\n",
            "        [0.7287],\n",
            "        [0.7427],\n",
            "        [0.7567],\n",
            "        [0.7707],\n",
            "        [0.7847],\n",
            "        [0.7986],\n",
            "        [0.8126],\n",
            "        [0.8266],\n",
            "        [0.8406],\n",
            "        [0.8546]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.2993],\n",
            "        [0.3132],\n",
            "        [0.3271],\n",
            "        [0.3410],\n",
            "        [0.3549],\n",
            "        [0.3688],\n",
            "        [0.3827],\n",
            "        [0.3966],\n",
            "        [0.4105],\n",
            "        [0.4244],\n",
            "        [0.4383],\n",
            "        [0.4522],\n",
            "        [0.4661],\n",
            "        [0.4800],\n",
            "        [0.4939],\n",
            "        [0.5078],\n",
            "        [0.5218],\n",
            "        [0.5357],\n",
            "        [0.5496],\n",
            "        [0.5635],\n",
            "        [0.5774],\n",
            "        [0.5913],\n",
            "        [0.6052],\n",
            "        [0.6191],\n",
            "        [0.6330],\n",
            "        [0.6469],\n",
            "        [0.6608],\n",
            "        [0.6747],\n",
            "        [0.6886],\n",
            "        [0.7025],\n",
            "        [0.7164],\n",
            "        [0.7303],\n",
            "        [0.7442],\n",
            "        [0.7581],\n",
            "        [0.7720],\n",
            "        [0.7859],\n",
            "        [0.7998],\n",
            "        [0.8137],\n",
            "        [0.8276],\n",
            "        [0.8415]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3093],\n",
            "        [0.3233],\n",
            "        [0.3373],\n",
            "        [0.3513],\n",
            "        [0.3652],\n",
            "        [0.3792],\n",
            "        [0.3932],\n",
            "        [0.4072],\n",
            "        [0.4212],\n",
            "        [0.4351],\n",
            "        [0.4491],\n",
            "        [0.4631],\n",
            "        [0.4771],\n",
            "        [0.4911],\n",
            "        [0.5050],\n",
            "        [0.5190],\n",
            "        [0.5330],\n",
            "        [0.5470],\n",
            "        [0.5610],\n",
            "        [0.5749],\n",
            "        [0.5889],\n",
            "        [0.6029],\n",
            "        [0.6169],\n",
            "        [0.6309],\n",
            "        [0.6448],\n",
            "        [0.6588],\n",
            "        [0.6728],\n",
            "        [0.6868],\n",
            "        [0.7008],\n",
            "        [0.7147],\n",
            "        [0.7287],\n",
            "        [0.7427],\n",
            "        [0.7567],\n",
            "        [0.7707],\n",
            "        [0.7847],\n",
            "        [0.7986],\n",
            "        [0.8126],\n",
            "        [0.8266],\n",
            "        [0.8406],\n",
            "        [0.8546]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.2993],\n",
            "        [0.3132],\n",
            "        [0.3271],\n",
            "        [0.3410],\n",
            "        [0.3549],\n",
            "        [0.3688],\n",
            "        [0.3827],\n",
            "        [0.3966],\n",
            "        [0.4105],\n",
            "        [0.4244],\n",
            "        [0.4383],\n",
            "        [0.4522],\n",
            "        [0.4661],\n",
            "        [0.4800],\n",
            "        [0.4939],\n",
            "        [0.5078],\n",
            "        [0.5218],\n",
            "        [0.5357],\n",
            "        [0.5496],\n",
            "        [0.5635],\n",
            "        [0.5774],\n",
            "        [0.5913],\n",
            "        [0.6052],\n",
            "        [0.6191],\n",
            "        [0.6330],\n",
            "        [0.6469],\n",
            "        [0.6608],\n",
            "        [0.6747],\n",
            "        [0.6886],\n",
            "        [0.7025],\n",
            "        [0.7164],\n",
            "        [0.7303],\n",
            "        [0.7442],\n",
            "        [0.7581],\n",
            "        [0.7720],\n",
            "        [0.7859],\n",
            "        [0.7998],\n",
            "        [0.8137],\n",
            "        [0.8276],\n",
            "        [0.8415]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3093],\n",
            "        [0.3233],\n",
            "        [0.3373],\n",
            "        [0.3513],\n",
            "        [0.3652],\n",
            "        [0.3792],\n",
            "        [0.3932],\n",
            "        [0.4072],\n",
            "        [0.4212],\n",
            "        [0.4351],\n",
            "        [0.4491],\n",
            "        [0.4631],\n",
            "        [0.4771],\n",
            "        [0.4911],\n",
            "        [0.5050],\n",
            "        [0.5190],\n",
            "        [0.5330],\n",
            "        [0.5470],\n",
            "        [0.5610],\n",
            "        [0.5749],\n",
            "        [0.5889],\n",
            "        [0.6029],\n",
            "        [0.6169],\n",
            "        [0.6309],\n",
            "        [0.6448],\n",
            "        [0.6588],\n",
            "        [0.6728],\n",
            "        [0.6868],\n",
            "        [0.7008],\n",
            "        [0.7147],\n",
            "        [0.7287],\n",
            "        [0.7427],\n",
            "        [0.7567],\n",
            "        [0.7707],\n",
            "        [0.7847],\n",
            "        [0.7986],\n",
            "        [0.8126],\n",
            "        [0.8266],\n",
            "        [0.8406],\n",
            "        [0.8546]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.2993],\n",
            "        [0.3132],\n",
            "        [0.3271],\n",
            "        [0.3410],\n",
            "        [0.3549],\n",
            "        [0.3688],\n",
            "        [0.3827],\n",
            "        [0.3966],\n",
            "        [0.4105],\n",
            "        [0.4244],\n",
            "        [0.4383],\n",
            "        [0.4522],\n",
            "        [0.4661],\n",
            "        [0.4800],\n",
            "        [0.4939],\n",
            "        [0.5078],\n",
            "        [0.5218],\n",
            "        [0.5357],\n",
            "        [0.5496],\n",
            "        [0.5635],\n",
            "        [0.5774],\n",
            "        [0.5913],\n",
            "        [0.6052],\n",
            "        [0.6191],\n",
            "        [0.6330],\n",
            "        [0.6469],\n",
            "        [0.6608],\n",
            "        [0.6747],\n",
            "        [0.6886],\n",
            "        [0.7025],\n",
            "        [0.7164],\n",
            "        [0.7303],\n",
            "        [0.7442],\n",
            "        [0.7581],\n",
            "        [0.7720],\n",
            "        [0.7859],\n",
            "        [0.7998],\n",
            "        [0.8137],\n",
            "        [0.8276],\n",
            "        [0.8415]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3093],\n",
            "        [0.3233],\n",
            "        [0.3373],\n",
            "        [0.3513],\n",
            "        [0.3652],\n",
            "        [0.3792],\n",
            "        [0.3932],\n",
            "        [0.4072],\n",
            "        [0.4212],\n",
            "        [0.4351],\n",
            "        [0.4491],\n",
            "        [0.4631],\n",
            "        [0.4771],\n",
            "        [0.4911],\n",
            "        [0.5050],\n",
            "        [0.5190],\n",
            "        [0.5330],\n",
            "        [0.5470],\n",
            "        [0.5610],\n",
            "        [0.5749],\n",
            "        [0.5889],\n",
            "        [0.6029],\n",
            "        [0.6169],\n",
            "        [0.6309],\n",
            "        [0.6448],\n",
            "        [0.6588],\n",
            "        [0.6728],\n",
            "        [0.6868],\n",
            "        [0.7008],\n",
            "        [0.7147],\n",
            "        [0.7287],\n",
            "        [0.7427],\n",
            "        [0.7567],\n",
            "        [0.7707],\n",
            "        [0.7847],\n",
            "        [0.7986],\n",
            "        [0.8126],\n",
            "        [0.8266],\n",
            "        [0.8406],\n",
            "        [0.8546]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.2993],\n",
            "        [0.3132],\n",
            "        [0.3271],\n",
            "        [0.3410],\n",
            "        [0.3549],\n",
            "        [0.3688],\n",
            "        [0.3827],\n",
            "        [0.3966],\n",
            "        [0.4105],\n",
            "        [0.4244],\n",
            "        [0.4383],\n",
            "        [0.4522],\n",
            "        [0.4661],\n",
            "        [0.4800],\n",
            "        [0.4939],\n",
            "        [0.5078],\n",
            "        [0.5218],\n",
            "        [0.5357],\n",
            "        [0.5496],\n",
            "        [0.5635],\n",
            "        [0.5774],\n",
            "        [0.5913],\n",
            "        [0.6052],\n",
            "        [0.6191],\n",
            "        [0.6330],\n",
            "        [0.6469],\n",
            "        [0.6608],\n",
            "        [0.6747],\n",
            "        [0.6886],\n",
            "        [0.7025],\n",
            "        [0.7164],\n",
            "        [0.7303],\n",
            "        [0.7442],\n",
            "        [0.7581],\n",
            "        [0.7720],\n",
            "        [0.7859],\n",
            "        [0.7998],\n",
            "        [0.8137],\n",
            "        [0.8276],\n",
            "        [0.8415]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3093],\n",
            "        [0.3233],\n",
            "        [0.3373],\n",
            "        [0.3513],\n",
            "        [0.3652],\n",
            "        [0.3792],\n",
            "        [0.3932],\n",
            "        [0.4072],\n",
            "        [0.4212],\n",
            "        [0.4351],\n",
            "        [0.4491],\n",
            "        [0.4631],\n",
            "        [0.4771],\n",
            "        [0.4911],\n",
            "        [0.5050],\n",
            "        [0.5190],\n",
            "        [0.5330],\n",
            "        [0.5470],\n",
            "        [0.5610],\n",
            "        [0.5749],\n",
            "        [0.5889],\n",
            "        [0.6029],\n",
            "        [0.6169],\n",
            "        [0.6309],\n",
            "        [0.6448],\n",
            "        [0.6588],\n",
            "        [0.6728],\n",
            "        [0.6868],\n",
            "        [0.7008],\n",
            "        [0.7147],\n",
            "        [0.7287],\n",
            "        [0.7427],\n",
            "        [0.7567],\n",
            "        [0.7707],\n",
            "        [0.7847],\n",
            "        [0.7986],\n",
            "        [0.8126],\n",
            "        [0.8266],\n",
            "        [0.8406],\n",
            "        [0.8546]], grad_fn=<AddBackward0>)\n",
            "Epoch: 260 | MAE Train Loss: 0.008932482451200485 | MAE Test Loss: 0.005023092031478882\n",
            "tensor([[0.2993],\n",
            "        [0.3132],\n",
            "        [0.3271],\n",
            "        [0.3410],\n",
            "        [0.3549],\n",
            "        [0.3688],\n",
            "        [0.3827],\n",
            "        [0.3966],\n",
            "        [0.4105],\n",
            "        [0.4244],\n",
            "        [0.4383],\n",
            "        [0.4522],\n",
            "        [0.4661],\n",
            "        [0.4800],\n",
            "        [0.4939],\n",
            "        [0.5078],\n",
            "        [0.5218],\n",
            "        [0.5357],\n",
            "        [0.5496],\n",
            "        [0.5635],\n",
            "        [0.5774],\n",
            "        [0.5913],\n",
            "        [0.6052],\n",
            "        [0.6191],\n",
            "        [0.6330],\n",
            "        [0.6469],\n",
            "        [0.6608],\n",
            "        [0.6747],\n",
            "        [0.6886],\n",
            "        [0.7025],\n",
            "        [0.7164],\n",
            "        [0.7303],\n",
            "        [0.7442],\n",
            "        [0.7581],\n",
            "        [0.7720],\n",
            "        [0.7859],\n",
            "        [0.7998],\n",
            "        [0.8137],\n",
            "        [0.8276],\n",
            "        [0.8415]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3093],\n",
            "        [0.3233],\n",
            "        [0.3373],\n",
            "        [0.3513],\n",
            "        [0.3652],\n",
            "        [0.3792],\n",
            "        [0.3932],\n",
            "        [0.4072],\n",
            "        [0.4212],\n",
            "        [0.4351],\n",
            "        [0.4491],\n",
            "        [0.4631],\n",
            "        [0.4771],\n",
            "        [0.4911],\n",
            "        [0.5050],\n",
            "        [0.5190],\n",
            "        [0.5330],\n",
            "        [0.5470],\n",
            "        [0.5610],\n",
            "        [0.5749],\n",
            "        [0.5889],\n",
            "        [0.6029],\n",
            "        [0.6169],\n",
            "        [0.6309],\n",
            "        [0.6448],\n",
            "        [0.6588],\n",
            "        [0.6728],\n",
            "        [0.6868],\n",
            "        [0.7008],\n",
            "        [0.7147],\n",
            "        [0.7287],\n",
            "        [0.7427],\n",
            "        [0.7567],\n",
            "        [0.7707],\n",
            "        [0.7847],\n",
            "        [0.7986],\n",
            "        [0.8126],\n",
            "        [0.8266],\n",
            "        [0.8406],\n",
            "        [0.8546]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.2993],\n",
            "        [0.3132],\n",
            "        [0.3271],\n",
            "        [0.3410],\n",
            "        [0.3549],\n",
            "        [0.3688],\n",
            "        [0.3827],\n",
            "        [0.3966],\n",
            "        [0.4105],\n",
            "        [0.4244],\n",
            "        [0.4383],\n",
            "        [0.4522],\n",
            "        [0.4661],\n",
            "        [0.4800],\n",
            "        [0.4939],\n",
            "        [0.5078],\n",
            "        [0.5218],\n",
            "        [0.5357],\n",
            "        [0.5496],\n",
            "        [0.5635],\n",
            "        [0.5774],\n",
            "        [0.5913],\n",
            "        [0.6052],\n",
            "        [0.6191],\n",
            "        [0.6330],\n",
            "        [0.6469],\n",
            "        [0.6608],\n",
            "        [0.6747],\n",
            "        [0.6886],\n",
            "        [0.7025],\n",
            "        [0.7164],\n",
            "        [0.7303],\n",
            "        [0.7442],\n",
            "        [0.7581],\n",
            "        [0.7720],\n",
            "        [0.7859],\n",
            "        [0.7998],\n",
            "        [0.8137],\n",
            "        [0.8276],\n",
            "        [0.8415]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3093],\n",
            "        [0.3233],\n",
            "        [0.3373],\n",
            "        [0.3513],\n",
            "        [0.3652],\n",
            "        [0.3792],\n",
            "        [0.3932],\n",
            "        [0.4072],\n",
            "        [0.4212],\n",
            "        [0.4351],\n",
            "        [0.4491],\n",
            "        [0.4631],\n",
            "        [0.4771],\n",
            "        [0.4911],\n",
            "        [0.5050],\n",
            "        [0.5190],\n",
            "        [0.5330],\n",
            "        [0.5470],\n",
            "        [0.5610],\n",
            "        [0.5749],\n",
            "        [0.5889],\n",
            "        [0.6029],\n",
            "        [0.6169],\n",
            "        [0.6309],\n",
            "        [0.6448],\n",
            "        [0.6588],\n",
            "        [0.6728],\n",
            "        [0.6868],\n",
            "        [0.7008],\n",
            "        [0.7147],\n",
            "        [0.7287],\n",
            "        [0.7427],\n",
            "        [0.7567],\n",
            "        [0.7707],\n",
            "        [0.7847],\n",
            "        [0.7986],\n",
            "        [0.8126],\n",
            "        [0.8266],\n",
            "        [0.8406],\n",
            "        [0.8546]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.2993],\n",
            "        [0.3132],\n",
            "        [0.3271],\n",
            "        [0.3410],\n",
            "        [0.3549],\n",
            "        [0.3688],\n",
            "        [0.3827],\n",
            "        [0.3966],\n",
            "        [0.4105],\n",
            "        [0.4244],\n",
            "        [0.4383],\n",
            "        [0.4522],\n",
            "        [0.4661],\n",
            "        [0.4800],\n",
            "        [0.4939],\n",
            "        [0.5078],\n",
            "        [0.5218],\n",
            "        [0.5357],\n",
            "        [0.5496],\n",
            "        [0.5635],\n",
            "        [0.5774],\n",
            "        [0.5913],\n",
            "        [0.6052],\n",
            "        [0.6191],\n",
            "        [0.6330],\n",
            "        [0.6469],\n",
            "        [0.6608],\n",
            "        [0.6747],\n",
            "        [0.6886],\n",
            "        [0.7025],\n",
            "        [0.7164],\n",
            "        [0.7303],\n",
            "        [0.7442],\n",
            "        [0.7581],\n",
            "        [0.7720],\n",
            "        [0.7859],\n",
            "        [0.7998],\n",
            "        [0.8137],\n",
            "        [0.8276],\n",
            "        [0.8415]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3093],\n",
            "        [0.3233],\n",
            "        [0.3373],\n",
            "        [0.3513],\n",
            "        [0.3652],\n",
            "        [0.3792],\n",
            "        [0.3932],\n",
            "        [0.4072],\n",
            "        [0.4212],\n",
            "        [0.4351],\n",
            "        [0.4491],\n",
            "        [0.4631],\n",
            "        [0.4771],\n",
            "        [0.4911],\n",
            "        [0.5050],\n",
            "        [0.5190],\n",
            "        [0.5330],\n",
            "        [0.5470],\n",
            "        [0.5610],\n",
            "        [0.5749],\n",
            "        [0.5889],\n",
            "        [0.6029],\n",
            "        [0.6169],\n",
            "        [0.6309],\n",
            "        [0.6448],\n",
            "        [0.6588],\n",
            "        [0.6728],\n",
            "        [0.6868],\n",
            "        [0.7008],\n",
            "        [0.7147],\n",
            "        [0.7287],\n",
            "        [0.7427],\n",
            "        [0.7567],\n",
            "        [0.7707],\n",
            "        [0.7847],\n",
            "        [0.7986],\n",
            "        [0.8126],\n",
            "        [0.8266],\n",
            "        [0.8406],\n",
            "        [0.8546]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.2993],\n",
            "        [0.3132],\n",
            "        [0.3271],\n",
            "        [0.3410],\n",
            "        [0.3549],\n",
            "        [0.3688],\n",
            "        [0.3827],\n",
            "        [0.3966],\n",
            "        [0.4105],\n",
            "        [0.4244],\n",
            "        [0.4383],\n",
            "        [0.4522],\n",
            "        [0.4661],\n",
            "        [0.4800],\n",
            "        [0.4939],\n",
            "        [0.5078],\n",
            "        [0.5218],\n",
            "        [0.5357],\n",
            "        [0.5496],\n",
            "        [0.5635],\n",
            "        [0.5774],\n",
            "        [0.5913],\n",
            "        [0.6052],\n",
            "        [0.6191],\n",
            "        [0.6330],\n",
            "        [0.6469],\n",
            "        [0.6608],\n",
            "        [0.6747],\n",
            "        [0.6886],\n",
            "        [0.7025],\n",
            "        [0.7164],\n",
            "        [0.7303],\n",
            "        [0.7442],\n",
            "        [0.7581],\n",
            "        [0.7720],\n",
            "        [0.7859],\n",
            "        [0.7998],\n",
            "        [0.8137],\n",
            "        [0.8276],\n",
            "        [0.8415]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3093],\n",
            "        [0.3233],\n",
            "        [0.3373],\n",
            "        [0.3513],\n",
            "        [0.3652],\n",
            "        [0.3792],\n",
            "        [0.3932],\n",
            "        [0.4072],\n",
            "        [0.4212],\n",
            "        [0.4351],\n",
            "        [0.4491],\n",
            "        [0.4631],\n",
            "        [0.4771],\n",
            "        [0.4911],\n",
            "        [0.5050],\n",
            "        [0.5190],\n",
            "        [0.5330],\n",
            "        [0.5470],\n",
            "        [0.5610],\n",
            "        [0.5749],\n",
            "        [0.5889],\n",
            "        [0.6029],\n",
            "        [0.6169],\n",
            "        [0.6309],\n",
            "        [0.6448],\n",
            "        [0.6588],\n",
            "        [0.6728],\n",
            "        [0.6868],\n",
            "        [0.7008],\n",
            "        [0.7147],\n",
            "        [0.7287],\n",
            "        [0.7427],\n",
            "        [0.7567],\n",
            "        [0.7707],\n",
            "        [0.7847],\n",
            "        [0.7986],\n",
            "        [0.8126],\n",
            "        [0.8266],\n",
            "        [0.8406],\n",
            "        [0.8546]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.2993],\n",
            "        [0.3132],\n",
            "        [0.3271],\n",
            "        [0.3410],\n",
            "        [0.3549],\n",
            "        [0.3688],\n",
            "        [0.3827],\n",
            "        [0.3966],\n",
            "        [0.4105],\n",
            "        [0.4244],\n",
            "        [0.4383],\n",
            "        [0.4522],\n",
            "        [0.4661],\n",
            "        [0.4800],\n",
            "        [0.4939],\n",
            "        [0.5078],\n",
            "        [0.5218],\n",
            "        [0.5357],\n",
            "        [0.5496],\n",
            "        [0.5635],\n",
            "        [0.5774],\n",
            "        [0.5913],\n",
            "        [0.6052],\n",
            "        [0.6191],\n",
            "        [0.6330],\n",
            "        [0.6469],\n",
            "        [0.6608],\n",
            "        [0.6747],\n",
            "        [0.6886],\n",
            "        [0.7025],\n",
            "        [0.7164],\n",
            "        [0.7303],\n",
            "        [0.7442],\n",
            "        [0.7581],\n",
            "        [0.7720],\n",
            "        [0.7859],\n",
            "        [0.7998],\n",
            "        [0.8137],\n",
            "        [0.8276],\n",
            "        [0.8415]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3093],\n",
            "        [0.3233],\n",
            "        [0.3373],\n",
            "        [0.3513],\n",
            "        [0.3652],\n",
            "        [0.3792],\n",
            "        [0.3932],\n",
            "        [0.4072],\n",
            "        [0.4212],\n",
            "        [0.4351],\n",
            "        [0.4491],\n",
            "        [0.4631],\n",
            "        [0.4771],\n",
            "        [0.4911],\n",
            "        [0.5050],\n",
            "        [0.5190],\n",
            "        [0.5330],\n",
            "        [0.5470],\n",
            "        [0.5610],\n",
            "        [0.5749],\n",
            "        [0.5889],\n",
            "        [0.6029],\n",
            "        [0.6169],\n",
            "        [0.6309],\n",
            "        [0.6448],\n",
            "        [0.6588],\n",
            "        [0.6728],\n",
            "        [0.6868],\n",
            "        [0.7008],\n",
            "        [0.7147],\n",
            "        [0.7287],\n",
            "        [0.7427],\n",
            "        [0.7567],\n",
            "        [0.7707],\n",
            "        [0.7847],\n",
            "        [0.7986],\n",
            "        [0.8126],\n",
            "        [0.8266],\n",
            "        [0.8406],\n",
            "        [0.8546]], grad_fn=<AddBackward0>)\n",
            "Epoch: 270 | MAE Train Loss: 0.008932482451200485 | MAE Test Loss: 0.005023092031478882\n",
            "tensor([[0.2993],\n",
            "        [0.3132],\n",
            "        [0.3271],\n",
            "        [0.3410],\n",
            "        [0.3549],\n",
            "        [0.3688],\n",
            "        [0.3827],\n",
            "        [0.3966],\n",
            "        [0.4105],\n",
            "        [0.4244],\n",
            "        [0.4383],\n",
            "        [0.4522],\n",
            "        [0.4661],\n",
            "        [0.4800],\n",
            "        [0.4939],\n",
            "        [0.5078],\n",
            "        [0.5218],\n",
            "        [0.5357],\n",
            "        [0.5496],\n",
            "        [0.5635],\n",
            "        [0.5774],\n",
            "        [0.5913],\n",
            "        [0.6052],\n",
            "        [0.6191],\n",
            "        [0.6330],\n",
            "        [0.6469],\n",
            "        [0.6608],\n",
            "        [0.6747],\n",
            "        [0.6886],\n",
            "        [0.7025],\n",
            "        [0.7164],\n",
            "        [0.7303],\n",
            "        [0.7442],\n",
            "        [0.7581],\n",
            "        [0.7720],\n",
            "        [0.7859],\n",
            "        [0.7998],\n",
            "        [0.8137],\n",
            "        [0.8276],\n",
            "        [0.8415]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3093],\n",
            "        [0.3233],\n",
            "        [0.3373],\n",
            "        [0.3513],\n",
            "        [0.3652],\n",
            "        [0.3792],\n",
            "        [0.3932],\n",
            "        [0.4072],\n",
            "        [0.4212],\n",
            "        [0.4351],\n",
            "        [0.4491],\n",
            "        [0.4631],\n",
            "        [0.4771],\n",
            "        [0.4911],\n",
            "        [0.5050],\n",
            "        [0.5190],\n",
            "        [0.5330],\n",
            "        [0.5470],\n",
            "        [0.5610],\n",
            "        [0.5749],\n",
            "        [0.5889],\n",
            "        [0.6029],\n",
            "        [0.6169],\n",
            "        [0.6309],\n",
            "        [0.6448],\n",
            "        [0.6588],\n",
            "        [0.6728],\n",
            "        [0.6868],\n",
            "        [0.7008],\n",
            "        [0.7147],\n",
            "        [0.7287],\n",
            "        [0.7427],\n",
            "        [0.7567],\n",
            "        [0.7707],\n",
            "        [0.7847],\n",
            "        [0.7986],\n",
            "        [0.8126],\n",
            "        [0.8266],\n",
            "        [0.8406],\n",
            "        [0.8546]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.2993],\n",
            "        [0.3132],\n",
            "        [0.3271],\n",
            "        [0.3410],\n",
            "        [0.3549],\n",
            "        [0.3688],\n",
            "        [0.3827],\n",
            "        [0.3966],\n",
            "        [0.4105],\n",
            "        [0.4244],\n",
            "        [0.4383],\n",
            "        [0.4522],\n",
            "        [0.4661],\n",
            "        [0.4800],\n",
            "        [0.4939],\n",
            "        [0.5078],\n",
            "        [0.5218],\n",
            "        [0.5357],\n",
            "        [0.5496],\n",
            "        [0.5635],\n",
            "        [0.5774],\n",
            "        [0.5913],\n",
            "        [0.6052],\n",
            "        [0.6191],\n",
            "        [0.6330],\n",
            "        [0.6469],\n",
            "        [0.6608],\n",
            "        [0.6747],\n",
            "        [0.6886],\n",
            "        [0.7025],\n",
            "        [0.7164],\n",
            "        [0.7303],\n",
            "        [0.7442],\n",
            "        [0.7581],\n",
            "        [0.7720],\n",
            "        [0.7859],\n",
            "        [0.7998],\n",
            "        [0.8137],\n",
            "        [0.8276],\n",
            "        [0.8415]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3093],\n",
            "        [0.3233],\n",
            "        [0.3373],\n",
            "        [0.3513],\n",
            "        [0.3652],\n",
            "        [0.3792],\n",
            "        [0.3932],\n",
            "        [0.4072],\n",
            "        [0.4212],\n",
            "        [0.4351],\n",
            "        [0.4491],\n",
            "        [0.4631],\n",
            "        [0.4771],\n",
            "        [0.4911],\n",
            "        [0.5050],\n",
            "        [0.5190],\n",
            "        [0.5330],\n",
            "        [0.5470],\n",
            "        [0.5610],\n",
            "        [0.5749],\n",
            "        [0.5889],\n",
            "        [0.6029],\n",
            "        [0.6169],\n",
            "        [0.6309],\n",
            "        [0.6448],\n",
            "        [0.6588],\n",
            "        [0.6728],\n",
            "        [0.6868],\n",
            "        [0.7008],\n",
            "        [0.7147],\n",
            "        [0.7287],\n",
            "        [0.7427],\n",
            "        [0.7567],\n",
            "        [0.7707],\n",
            "        [0.7847],\n",
            "        [0.7986],\n",
            "        [0.8126],\n",
            "        [0.8266],\n",
            "        [0.8406],\n",
            "        [0.8546]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.2993],\n",
            "        [0.3132],\n",
            "        [0.3271],\n",
            "        [0.3410],\n",
            "        [0.3549],\n",
            "        [0.3688],\n",
            "        [0.3827],\n",
            "        [0.3966],\n",
            "        [0.4105],\n",
            "        [0.4244],\n",
            "        [0.4383],\n",
            "        [0.4522],\n",
            "        [0.4661],\n",
            "        [0.4800],\n",
            "        [0.4939],\n",
            "        [0.5078],\n",
            "        [0.5218],\n",
            "        [0.5357],\n",
            "        [0.5496],\n",
            "        [0.5635],\n",
            "        [0.5774],\n",
            "        [0.5913],\n",
            "        [0.6052],\n",
            "        [0.6191],\n",
            "        [0.6330],\n",
            "        [0.6469],\n",
            "        [0.6608],\n",
            "        [0.6747],\n",
            "        [0.6886],\n",
            "        [0.7025],\n",
            "        [0.7164],\n",
            "        [0.7303],\n",
            "        [0.7442],\n",
            "        [0.7581],\n",
            "        [0.7720],\n",
            "        [0.7859],\n",
            "        [0.7998],\n",
            "        [0.8137],\n",
            "        [0.8276],\n",
            "        [0.8415]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3093],\n",
            "        [0.3233],\n",
            "        [0.3373],\n",
            "        [0.3513],\n",
            "        [0.3652],\n",
            "        [0.3792],\n",
            "        [0.3932],\n",
            "        [0.4072],\n",
            "        [0.4212],\n",
            "        [0.4351],\n",
            "        [0.4491],\n",
            "        [0.4631],\n",
            "        [0.4771],\n",
            "        [0.4911],\n",
            "        [0.5050],\n",
            "        [0.5190],\n",
            "        [0.5330],\n",
            "        [0.5470],\n",
            "        [0.5610],\n",
            "        [0.5749],\n",
            "        [0.5889],\n",
            "        [0.6029],\n",
            "        [0.6169],\n",
            "        [0.6309],\n",
            "        [0.6448],\n",
            "        [0.6588],\n",
            "        [0.6728],\n",
            "        [0.6868],\n",
            "        [0.7008],\n",
            "        [0.7147],\n",
            "        [0.7287],\n",
            "        [0.7427],\n",
            "        [0.7567],\n",
            "        [0.7707],\n",
            "        [0.7847],\n",
            "        [0.7986],\n",
            "        [0.8126],\n",
            "        [0.8266],\n",
            "        [0.8406],\n",
            "        [0.8546]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.2993],\n",
            "        [0.3132],\n",
            "        [0.3271],\n",
            "        [0.3410],\n",
            "        [0.3549],\n",
            "        [0.3688],\n",
            "        [0.3827],\n",
            "        [0.3966],\n",
            "        [0.4105],\n",
            "        [0.4244],\n",
            "        [0.4383],\n",
            "        [0.4522],\n",
            "        [0.4661],\n",
            "        [0.4800],\n",
            "        [0.4939],\n",
            "        [0.5078],\n",
            "        [0.5218],\n",
            "        [0.5357],\n",
            "        [0.5496],\n",
            "        [0.5635],\n",
            "        [0.5774],\n",
            "        [0.5913],\n",
            "        [0.6052],\n",
            "        [0.6191],\n",
            "        [0.6330],\n",
            "        [0.6469],\n",
            "        [0.6608],\n",
            "        [0.6747],\n",
            "        [0.6886],\n",
            "        [0.7025],\n",
            "        [0.7164],\n",
            "        [0.7303],\n",
            "        [0.7442],\n",
            "        [0.7581],\n",
            "        [0.7720],\n",
            "        [0.7859],\n",
            "        [0.7998],\n",
            "        [0.8137],\n",
            "        [0.8276],\n",
            "        [0.8415]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3093],\n",
            "        [0.3233],\n",
            "        [0.3373],\n",
            "        [0.3513],\n",
            "        [0.3652],\n",
            "        [0.3792],\n",
            "        [0.3932],\n",
            "        [0.4072],\n",
            "        [0.4212],\n",
            "        [0.4351],\n",
            "        [0.4491],\n",
            "        [0.4631],\n",
            "        [0.4771],\n",
            "        [0.4911],\n",
            "        [0.5050],\n",
            "        [0.5190],\n",
            "        [0.5330],\n",
            "        [0.5470],\n",
            "        [0.5610],\n",
            "        [0.5749],\n",
            "        [0.5889],\n",
            "        [0.6029],\n",
            "        [0.6169],\n",
            "        [0.6309],\n",
            "        [0.6448],\n",
            "        [0.6588],\n",
            "        [0.6728],\n",
            "        [0.6868],\n",
            "        [0.7008],\n",
            "        [0.7147],\n",
            "        [0.7287],\n",
            "        [0.7427],\n",
            "        [0.7567],\n",
            "        [0.7707],\n",
            "        [0.7847],\n",
            "        [0.7986],\n",
            "        [0.8126],\n",
            "        [0.8266],\n",
            "        [0.8406],\n",
            "        [0.8546]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.2993],\n",
            "        [0.3132],\n",
            "        [0.3271],\n",
            "        [0.3410],\n",
            "        [0.3549],\n",
            "        [0.3688],\n",
            "        [0.3827],\n",
            "        [0.3966],\n",
            "        [0.4105],\n",
            "        [0.4244],\n",
            "        [0.4383],\n",
            "        [0.4522],\n",
            "        [0.4661],\n",
            "        [0.4800],\n",
            "        [0.4939],\n",
            "        [0.5078],\n",
            "        [0.5218],\n",
            "        [0.5357],\n",
            "        [0.5496],\n",
            "        [0.5635],\n",
            "        [0.5774],\n",
            "        [0.5913],\n",
            "        [0.6052],\n",
            "        [0.6191],\n",
            "        [0.6330],\n",
            "        [0.6469],\n",
            "        [0.6608],\n",
            "        [0.6747],\n",
            "        [0.6886],\n",
            "        [0.7025],\n",
            "        [0.7164],\n",
            "        [0.7303],\n",
            "        [0.7442],\n",
            "        [0.7581],\n",
            "        [0.7720],\n",
            "        [0.7859],\n",
            "        [0.7998],\n",
            "        [0.8137],\n",
            "        [0.8276],\n",
            "        [0.8415]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3093],\n",
            "        [0.3233],\n",
            "        [0.3373],\n",
            "        [0.3513],\n",
            "        [0.3652],\n",
            "        [0.3792],\n",
            "        [0.3932],\n",
            "        [0.4072],\n",
            "        [0.4212],\n",
            "        [0.4351],\n",
            "        [0.4491],\n",
            "        [0.4631],\n",
            "        [0.4771],\n",
            "        [0.4911],\n",
            "        [0.5050],\n",
            "        [0.5190],\n",
            "        [0.5330],\n",
            "        [0.5470],\n",
            "        [0.5610],\n",
            "        [0.5749],\n",
            "        [0.5889],\n",
            "        [0.6029],\n",
            "        [0.6169],\n",
            "        [0.6309],\n",
            "        [0.6448],\n",
            "        [0.6588],\n",
            "        [0.6728],\n",
            "        [0.6868],\n",
            "        [0.7008],\n",
            "        [0.7147],\n",
            "        [0.7287],\n",
            "        [0.7427],\n",
            "        [0.7567],\n",
            "        [0.7707],\n",
            "        [0.7847],\n",
            "        [0.7986],\n",
            "        [0.8126],\n",
            "        [0.8266],\n",
            "        [0.8406],\n",
            "        [0.8546]], grad_fn=<AddBackward0>)\n",
            "Epoch: 280 | MAE Train Loss: 0.008932482451200485 | MAE Test Loss: 0.005023092031478882\n",
            "tensor([[0.2993],\n",
            "        [0.3132],\n",
            "        [0.3271],\n",
            "        [0.3410],\n",
            "        [0.3549],\n",
            "        [0.3688],\n",
            "        [0.3827],\n",
            "        [0.3966],\n",
            "        [0.4105],\n",
            "        [0.4244],\n",
            "        [0.4383],\n",
            "        [0.4522],\n",
            "        [0.4661],\n",
            "        [0.4800],\n",
            "        [0.4939],\n",
            "        [0.5078],\n",
            "        [0.5218],\n",
            "        [0.5357],\n",
            "        [0.5496],\n",
            "        [0.5635],\n",
            "        [0.5774],\n",
            "        [0.5913],\n",
            "        [0.6052],\n",
            "        [0.6191],\n",
            "        [0.6330],\n",
            "        [0.6469],\n",
            "        [0.6608],\n",
            "        [0.6747],\n",
            "        [0.6886],\n",
            "        [0.7025],\n",
            "        [0.7164],\n",
            "        [0.7303],\n",
            "        [0.7442],\n",
            "        [0.7581],\n",
            "        [0.7720],\n",
            "        [0.7859],\n",
            "        [0.7998],\n",
            "        [0.8137],\n",
            "        [0.8276],\n",
            "        [0.8415]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3093],\n",
            "        [0.3233],\n",
            "        [0.3373],\n",
            "        [0.3513],\n",
            "        [0.3652],\n",
            "        [0.3792],\n",
            "        [0.3932],\n",
            "        [0.4072],\n",
            "        [0.4212],\n",
            "        [0.4351],\n",
            "        [0.4491],\n",
            "        [0.4631],\n",
            "        [0.4771],\n",
            "        [0.4911],\n",
            "        [0.5050],\n",
            "        [0.5190],\n",
            "        [0.5330],\n",
            "        [0.5470],\n",
            "        [0.5610],\n",
            "        [0.5749],\n",
            "        [0.5889],\n",
            "        [0.6029],\n",
            "        [0.6169],\n",
            "        [0.6309],\n",
            "        [0.6448],\n",
            "        [0.6588],\n",
            "        [0.6728],\n",
            "        [0.6868],\n",
            "        [0.7008],\n",
            "        [0.7147],\n",
            "        [0.7287],\n",
            "        [0.7427],\n",
            "        [0.7567],\n",
            "        [0.7707],\n",
            "        [0.7847],\n",
            "        [0.7986],\n",
            "        [0.8126],\n",
            "        [0.8266],\n",
            "        [0.8406],\n",
            "        [0.8546]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.2993],\n",
            "        [0.3132],\n",
            "        [0.3271],\n",
            "        [0.3410],\n",
            "        [0.3549],\n",
            "        [0.3688],\n",
            "        [0.3827],\n",
            "        [0.3966],\n",
            "        [0.4105],\n",
            "        [0.4244],\n",
            "        [0.4383],\n",
            "        [0.4522],\n",
            "        [0.4661],\n",
            "        [0.4800],\n",
            "        [0.4939],\n",
            "        [0.5078],\n",
            "        [0.5218],\n",
            "        [0.5357],\n",
            "        [0.5496],\n",
            "        [0.5635],\n",
            "        [0.5774],\n",
            "        [0.5913],\n",
            "        [0.6052],\n",
            "        [0.6191],\n",
            "        [0.6330],\n",
            "        [0.6469],\n",
            "        [0.6608],\n",
            "        [0.6747],\n",
            "        [0.6886],\n",
            "        [0.7025],\n",
            "        [0.7164],\n",
            "        [0.7303],\n",
            "        [0.7442],\n",
            "        [0.7581],\n",
            "        [0.7720],\n",
            "        [0.7859],\n",
            "        [0.7998],\n",
            "        [0.8137],\n",
            "        [0.8276],\n",
            "        [0.8415]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3093],\n",
            "        [0.3233],\n",
            "        [0.3373],\n",
            "        [0.3513],\n",
            "        [0.3652],\n",
            "        [0.3792],\n",
            "        [0.3932],\n",
            "        [0.4072],\n",
            "        [0.4212],\n",
            "        [0.4351],\n",
            "        [0.4491],\n",
            "        [0.4631],\n",
            "        [0.4771],\n",
            "        [0.4911],\n",
            "        [0.5050],\n",
            "        [0.5190],\n",
            "        [0.5330],\n",
            "        [0.5470],\n",
            "        [0.5610],\n",
            "        [0.5749],\n",
            "        [0.5889],\n",
            "        [0.6029],\n",
            "        [0.6169],\n",
            "        [0.6309],\n",
            "        [0.6448],\n",
            "        [0.6588],\n",
            "        [0.6728],\n",
            "        [0.6868],\n",
            "        [0.7008],\n",
            "        [0.7147],\n",
            "        [0.7287],\n",
            "        [0.7427],\n",
            "        [0.7567],\n",
            "        [0.7707],\n",
            "        [0.7847],\n",
            "        [0.7986],\n",
            "        [0.8126],\n",
            "        [0.8266],\n",
            "        [0.8406],\n",
            "        [0.8546]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.2993],\n",
            "        [0.3132],\n",
            "        [0.3271],\n",
            "        [0.3410],\n",
            "        [0.3549],\n",
            "        [0.3688],\n",
            "        [0.3827],\n",
            "        [0.3966],\n",
            "        [0.4105],\n",
            "        [0.4244],\n",
            "        [0.4383],\n",
            "        [0.4522],\n",
            "        [0.4661],\n",
            "        [0.4800],\n",
            "        [0.4939],\n",
            "        [0.5078],\n",
            "        [0.5218],\n",
            "        [0.5357],\n",
            "        [0.5496],\n",
            "        [0.5635],\n",
            "        [0.5774],\n",
            "        [0.5913],\n",
            "        [0.6052],\n",
            "        [0.6191],\n",
            "        [0.6330],\n",
            "        [0.6469],\n",
            "        [0.6608],\n",
            "        [0.6747],\n",
            "        [0.6886],\n",
            "        [0.7025],\n",
            "        [0.7164],\n",
            "        [0.7303],\n",
            "        [0.7442],\n",
            "        [0.7581],\n",
            "        [0.7720],\n",
            "        [0.7859],\n",
            "        [0.7998],\n",
            "        [0.8137],\n",
            "        [0.8276],\n",
            "        [0.8415]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3093],\n",
            "        [0.3233],\n",
            "        [0.3373],\n",
            "        [0.3513],\n",
            "        [0.3652],\n",
            "        [0.3792],\n",
            "        [0.3932],\n",
            "        [0.4072],\n",
            "        [0.4212],\n",
            "        [0.4351],\n",
            "        [0.4491],\n",
            "        [0.4631],\n",
            "        [0.4771],\n",
            "        [0.4911],\n",
            "        [0.5050],\n",
            "        [0.5190],\n",
            "        [0.5330],\n",
            "        [0.5470],\n",
            "        [0.5610],\n",
            "        [0.5749],\n",
            "        [0.5889],\n",
            "        [0.6029],\n",
            "        [0.6169],\n",
            "        [0.6309],\n",
            "        [0.6448],\n",
            "        [0.6588],\n",
            "        [0.6728],\n",
            "        [0.6868],\n",
            "        [0.7008],\n",
            "        [0.7147],\n",
            "        [0.7287],\n",
            "        [0.7427],\n",
            "        [0.7567],\n",
            "        [0.7707],\n",
            "        [0.7847],\n",
            "        [0.7986],\n",
            "        [0.8126],\n",
            "        [0.8266],\n",
            "        [0.8406],\n",
            "        [0.8546]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.2993],\n",
            "        [0.3132],\n",
            "        [0.3271],\n",
            "        [0.3410],\n",
            "        [0.3549],\n",
            "        [0.3688],\n",
            "        [0.3827],\n",
            "        [0.3966],\n",
            "        [0.4105],\n",
            "        [0.4244],\n",
            "        [0.4383],\n",
            "        [0.4522],\n",
            "        [0.4661],\n",
            "        [0.4800],\n",
            "        [0.4939],\n",
            "        [0.5078],\n",
            "        [0.5218],\n",
            "        [0.5357],\n",
            "        [0.5496],\n",
            "        [0.5635],\n",
            "        [0.5774],\n",
            "        [0.5913],\n",
            "        [0.6052],\n",
            "        [0.6191],\n",
            "        [0.6330],\n",
            "        [0.6469],\n",
            "        [0.6608],\n",
            "        [0.6747],\n",
            "        [0.6886],\n",
            "        [0.7025],\n",
            "        [0.7164],\n",
            "        [0.7303],\n",
            "        [0.7442],\n",
            "        [0.7581],\n",
            "        [0.7720],\n",
            "        [0.7859],\n",
            "        [0.7998],\n",
            "        [0.8137],\n",
            "        [0.8276],\n",
            "        [0.8415]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3093],\n",
            "        [0.3233],\n",
            "        [0.3373],\n",
            "        [0.3513],\n",
            "        [0.3652],\n",
            "        [0.3792],\n",
            "        [0.3932],\n",
            "        [0.4072],\n",
            "        [0.4212],\n",
            "        [0.4351],\n",
            "        [0.4491],\n",
            "        [0.4631],\n",
            "        [0.4771],\n",
            "        [0.4911],\n",
            "        [0.5050],\n",
            "        [0.5190],\n",
            "        [0.5330],\n",
            "        [0.5470],\n",
            "        [0.5610],\n",
            "        [0.5749],\n",
            "        [0.5889],\n",
            "        [0.6029],\n",
            "        [0.6169],\n",
            "        [0.6309],\n",
            "        [0.6448],\n",
            "        [0.6588],\n",
            "        [0.6728],\n",
            "        [0.6868],\n",
            "        [0.7008],\n",
            "        [0.7147],\n",
            "        [0.7287],\n",
            "        [0.7427],\n",
            "        [0.7567],\n",
            "        [0.7707],\n",
            "        [0.7847],\n",
            "        [0.7986],\n",
            "        [0.8126],\n",
            "        [0.8266],\n",
            "        [0.8406],\n",
            "        [0.8546]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.2993],\n",
            "        [0.3132],\n",
            "        [0.3271],\n",
            "        [0.3410],\n",
            "        [0.3549],\n",
            "        [0.3688],\n",
            "        [0.3827],\n",
            "        [0.3966],\n",
            "        [0.4105],\n",
            "        [0.4244],\n",
            "        [0.4383],\n",
            "        [0.4522],\n",
            "        [0.4661],\n",
            "        [0.4800],\n",
            "        [0.4939],\n",
            "        [0.5078],\n",
            "        [0.5218],\n",
            "        [0.5357],\n",
            "        [0.5496],\n",
            "        [0.5635],\n",
            "        [0.5774],\n",
            "        [0.5913],\n",
            "        [0.6052],\n",
            "        [0.6191],\n",
            "        [0.6330],\n",
            "        [0.6469],\n",
            "        [0.6608],\n",
            "        [0.6747],\n",
            "        [0.6886],\n",
            "        [0.7025],\n",
            "        [0.7164],\n",
            "        [0.7303],\n",
            "        [0.7442],\n",
            "        [0.7581],\n",
            "        [0.7720],\n",
            "        [0.7859],\n",
            "        [0.7998],\n",
            "        [0.8137],\n",
            "        [0.8276],\n",
            "        [0.8415]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3093],\n",
            "        [0.3233],\n",
            "        [0.3373],\n",
            "        [0.3513],\n",
            "        [0.3652],\n",
            "        [0.3792],\n",
            "        [0.3932],\n",
            "        [0.4072],\n",
            "        [0.4212],\n",
            "        [0.4351],\n",
            "        [0.4491],\n",
            "        [0.4631],\n",
            "        [0.4771],\n",
            "        [0.4911],\n",
            "        [0.5050],\n",
            "        [0.5190],\n",
            "        [0.5330],\n",
            "        [0.5470],\n",
            "        [0.5610],\n",
            "        [0.5749],\n",
            "        [0.5889],\n",
            "        [0.6029],\n",
            "        [0.6169],\n",
            "        [0.6309],\n",
            "        [0.6448],\n",
            "        [0.6588],\n",
            "        [0.6728],\n",
            "        [0.6868],\n",
            "        [0.7008],\n",
            "        [0.7147],\n",
            "        [0.7287],\n",
            "        [0.7427],\n",
            "        [0.7567],\n",
            "        [0.7707],\n",
            "        [0.7847],\n",
            "        [0.7986],\n",
            "        [0.8126],\n",
            "        [0.8266],\n",
            "        [0.8406],\n",
            "        [0.8546]], grad_fn=<AddBackward0>)\n",
            "Epoch: 290 | MAE Train Loss: 0.008932482451200485 | MAE Test Loss: 0.005023092031478882\n",
            "tensor([[0.2993],\n",
            "        [0.3132],\n",
            "        [0.3271],\n",
            "        [0.3410],\n",
            "        [0.3549],\n",
            "        [0.3688],\n",
            "        [0.3827],\n",
            "        [0.3966],\n",
            "        [0.4105],\n",
            "        [0.4244],\n",
            "        [0.4383],\n",
            "        [0.4522],\n",
            "        [0.4661],\n",
            "        [0.4800],\n",
            "        [0.4939],\n",
            "        [0.5078],\n",
            "        [0.5218],\n",
            "        [0.5357],\n",
            "        [0.5496],\n",
            "        [0.5635],\n",
            "        [0.5774],\n",
            "        [0.5913],\n",
            "        [0.6052],\n",
            "        [0.6191],\n",
            "        [0.6330],\n",
            "        [0.6469],\n",
            "        [0.6608],\n",
            "        [0.6747],\n",
            "        [0.6886],\n",
            "        [0.7025],\n",
            "        [0.7164],\n",
            "        [0.7303],\n",
            "        [0.7442],\n",
            "        [0.7581],\n",
            "        [0.7720],\n",
            "        [0.7859],\n",
            "        [0.7998],\n",
            "        [0.8137],\n",
            "        [0.8276],\n",
            "        [0.8415]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3093],\n",
            "        [0.3233],\n",
            "        [0.3373],\n",
            "        [0.3513],\n",
            "        [0.3652],\n",
            "        [0.3792],\n",
            "        [0.3932],\n",
            "        [0.4072],\n",
            "        [0.4212],\n",
            "        [0.4351],\n",
            "        [0.4491],\n",
            "        [0.4631],\n",
            "        [0.4771],\n",
            "        [0.4911],\n",
            "        [0.5050],\n",
            "        [0.5190],\n",
            "        [0.5330],\n",
            "        [0.5470],\n",
            "        [0.5610],\n",
            "        [0.5749],\n",
            "        [0.5889],\n",
            "        [0.6029],\n",
            "        [0.6169],\n",
            "        [0.6309],\n",
            "        [0.6448],\n",
            "        [0.6588],\n",
            "        [0.6728],\n",
            "        [0.6868],\n",
            "        [0.7008],\n",
            "        [0.7147],\n",
            "        [0.7287],\n",
            "        [0.7427],\n",
            "        [0.7567],\n",
            "        [0.7707],\n",
            "        [0.7847],\n",
            "        [0.7986],\n",
            "        [0.8126],\n",
            "        [0.8266],\n",
            "        [0.8406],\n",
            "        [0.8546]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.2993],\n",
            "        [0.3132],\n",
            "        [0.3271],\n",
            "        [0.3410],\n",
            "        [0.3549],\n",
            "        [0.3688],\n",
            "        [0.3827],\n",
            "        [0.3966],\n",
            "        [0.4105],\n",
            "        [0.4244],\n",
            "        [0.4383],\n",
            "        [0.4522],\n",
            "        [0.4661],\n",
            "        [0.4800],\n",
            "        [0.4939],\n",
            "        [0.5078],\n",
            "        [0.5218],\n",
            "        [0.5357],\n",
            "        [0.5496],\n",
            "        [0.5635],\n",
            "        [0.5774],\n",
            "        [0.5913],\n",
            "        [0.6052],\n",
            "        [0.6191],\n",
            "        [0.6330],\n",
            "        [0.6469],\n",
            "        [0.6608],\n",
            "        [0.6747],\n",
            "        [0.6886],\n",
            "        [0.7025],\n",
            "        [0.7164],\n",
            "        [0.7303],\n",
            "        [0.7442],\n",
            "        [0.7581],\n",
            "        [0.7720],\n",
            "        [0.7859],\n",
            "        [0.7998],\n",
            "        [0.8137],\n",
            "        [0.8276],\n",
            "        [0.8415]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3093],\n",
            "        [0.3233],\n",
            "        [0.3373],\n",
            "        [0.3513],\n",
            "        [0.3652],\n",
            "        [0.3792],\n",
            "        [0.3932],\n",
            "        [0.4072],\n",
            "        [0.4212],\n",
            "        [0.4351],\n",
            "        [0.4491],\n",
            "        [0.4631],\n",
            "        [0.4771],\n",
            "        [0.4911],\n",
            "        [0.5050],\n",
            "        [0.5190],\n",
            "        [0.5330],\n",
            "        [0.5470],\n",
            "        [0.5610],\n",
            "        [0.5749],\n",
            "        [0.5889],\n",
            "        [0.6029],\n",
            "        [0.6169],\n",
            "        [0.6309],\n",
            "        [0.6448],\n",
            "        [0.6588],\n",
            "        [0.6728],\n",
            "        [0.6868],\n",
            "        [0.7008],\n",
            "        [0.7147],\n",
            "        [0.7287],\n",
            "        [0.7427],\n",
            "        [0.7567],\n",
            "        [0.7707],\n",
            "        [0.7847],\n",
            "        [0.7986],\n",
            "        [0.8126],\n",
            "        [0.8266],\n",
            "        [0.8406],\n",
            "        [0.8546]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.2993],\n",
            "        [0.3132],\n",
            "        [0.3271],\n",
            "        [0.3410],\n",
            "        [0.3549],\n",
            "        [0.3688],\n",
            "        [0.3827],\n",
            "        [0.3966],\n",
            "        [0.4105],\n",
            "        [0.4244],\n",
            "        [0.4383],\n",
            "        [0.4522],\n",
            "        [0.4661],\n",
            "        [0.4800],\n",
            "        [0.4939],\n",
            "        [0.5078],\n",
            "        [0.5218],\n",
            "        [0.5357],\n",
            "        [0.5496],\n",
            "        [0.5635],\n",
            "        [0.5774],\n",
            "        [0.5913],\n",
            "        [0.6052],\n",
            "        [0.6191],\n",
            "        [0.6330],\n",
            "        [0.6469],\n",
            "        [0.6608],\n",
            "        [0.6747],\n",
            "        [0.6886],\n",
            "        [0.7025],\n",
            "        [0.7164],\n",
            "        [0.7303],\n",
            "        [0.7442],\n",
            "        [0.7581],\n",
            "        [0.7720],\n",
            "        [0.7859],\n",
            "        [0.7998],\n",
            "        [0.8137],\n",
            "        [0.8276],\n",
            "        [0.8415]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3093],\n",
            "        [0.3233],\n",
            "        [0.3373],\n",
            "        [0.3513],\n",
            "        [0.3652],\n",
            "        [0.3792],\n",
            "        [0.3932],\n",
            "        [0.4072],\n",
            "        [0.4212],\n",
            "        [0.4351],\n",
            "        [0.4491],\n",
            "        [0.4631],\n",
            "        [0.4771],\n",
            "        [0.4911],\n",
            "        [0.5050],\n",
            "        [0.5190],\n",
            "        [0.5330],\n",
            "        [0.5470],\n",
            "        [0.5610],\n",
            "        [0.5749],\n",
            "        [0.5889],\n",
            "        [0.6029],\n",
            "        [0.6169],\n",
            "        [0.6309],\n",
            "        [0.6448],\n",
            "        [0.6588],\n",
            "        [0.6728],\n",
            "        [0.6868],\n",
            "        [0.7008],\n",
            "        [0.7147],\n",
            "        [0.7287],\n",
            "        [0.7427],\n",
            "        [0.7567],\n",
            "        [0.7707],\n",
            "        [0.7847],\n",
            "        [0.7986],\n",
            "        [0.8126],\n",
            "        [0.8266],\n",
            "        [0.8406],\n",
            "        [0.8546]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.2993],\n",
            "        [0.3132],\n",
            "        [0.3271],\n",
            "        [0.3410],\n",
            "        [0.3549],\n",
            "        [0.3688],\n",
            "        [0.3827],\n",
            "        [0.3966],\n",
            "        [0.4105],\n",
            "        [0.4244],\n",
            "        [0.4383],\n",
            "        [0.4522],\n",
            "        [0.4661],\n",
            "        [0.4800],\n",
            "        [0.4939],\n",
            "        [0.5078],\n",
            "        [0.5218],\n",
            "        [0.5357],\n",
            "        [0.5496],\n",
            "        [0.5635],\n",
            "        [0.5774],\n",
            "        [0.5913],\n",
            "        [0.6052],\n",
            "        [0.6191],\n",
            "        [0.6330],\n",
            "        [0.6469],\n",
            "        [0.6608],\n",
            "        [0.6747],\n",
            "        [0.6886],\n",
            "        [0.7025],\n",
            "        [0.7164],\n",
            "        [0.7303],\n",
            "        [0.7442],\n",
            "        [0.7581],\n",
            "        [0.7720],\n",
            "        [0.7859],\n",
            "        [0.7998],\n",
            "        [0.8137],\n",
            "        [0.8276],\n",
            "        [0.8415]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.3093],\n",
            "        [0.3233],\n",
            "        [0.3373],\n",
            "        [0.3513],\n",
            "        [0.3652],\n",
            "        [0.3792],\n",
            "        [0.3932],\n",
            "        [0.4072],\n",
            "        [0.4212],\n",
            "        [0.4351],\n",
            "        [0.4491],\n",
            "        [0.4631],\n",
            "        [0.4771],\n",
            "        [0.4911],\n",
            "        [0.5050],\n",
            "        [0.5190],\n",
            "        [0.5330],\n",
            "        [0.5470],\n",
            "        [0.5610],\n",
            "        [0.5749],\n",
            "        [0.5889],\n",
            "        [0.6029],\n",
            "        [0.6169],\n",
            "        [0.6309],\n",
            "        [0.6448],\n",
            "        [0.6588],\n",
            "        [0.6728],\n",
            "        [0.6868],\n",
            "        [0.7008],\n",
            "        [0.7147],\n",
            "        [0.7287],\n",
            "        [0.7427],\n",
            "        [0.7567],\n",
            "        [0.7707],\n",
            "        [0.7847],\n",
            "        [0.7986],\n",
            "        [0.8126],\n",
            "        [0.8266],\n",
            "        [0.8406],\n",
            "        [0.8546]], grad_fn=<AddBackward0>)\n",
            "tensor([[0.2993],\n",
            "        [0.3132],\n",
            "        [0.3271],\n",
            "        [0.3410],\n",
            "        [0.3549],\n",
            "        [0.3688],\n",
            "        [0.3827],\n",
            "        [0.3966],\n",
            "        [0.4105],\n",
            "        [0.4244],\n",
            "        [0.4383],\n",
            "        [0.4522],\n",
            "        [0.4661],\n",
            "        [0.4800],\n",
            "        [0.4939],\n",
            "        [0.5078],\n",
            "        [0.5218],\n",
            "        [0.5357],\n",
            "        [0.5496],\n",
            "        [0.5635],\n",
            "        [0.5774],\n",
            "        [0.5913],\n",
            "        [0.6052],\n",
            "        [0.6191],\n",
            "        [0.6330],\n",
            "        [0.6469],\n",
            "        [0.6608],\n",
            "        [0.6747],\n",
            "        [0.6886],\n",
            "        [0.7025],\n",
            "        [0.7164],\n",
            "        [0.7303],\n",
            "        [0.7442],\n",
            "        [0.7581],\n",
            "        [0.7720],\n",
            "        [0.7859],\n",
            "        [0.7998],\n",
            "        [0.8137],\n",
            "        [0.8276],\n",
            "        [0.8415]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(epoch_count, train_loss_values, label=\"Train loss\")\n",
        "plt.plot(epoch_count, test_loss_values, label=\"Test loss\")\n",
        "plt.title(\"Training and Test loss curves\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Epohs\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "KqeRo0txjFPH",
        "outputId": "f08d5261-2439-48f0-9aba-c6c8732b54f2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7a3406e42c80>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# finding our model's learned parameters\n",
        "print(\"The model learned the following values for weights and bias: \")\n",
        "print(model_0.state_dict())\n",
        "print(\"\\nAnd the original values for weights and bias are:\")\n",
        "print(f\"Weights: {weight}, bias: {bias}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNiICilUjzSL",
        "outputId": "5f9437b4-2a02-4e55-b86c-6b034a395e18"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model learned the following values for weights and bias: \n",
            "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n",
            "\n",
            "And the original values for weights and bias are:\n",
            "Weights: 0.7, bias: 0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Making predictions with a trained PyTorch model(inference)\n",
        "# Setting the model in evaluation model\n",
        "model_0.eval()\n",
        "# Setup the inference mode context manager\n",
        "with torch.inference_mode():\n",
        "  y_preds = model_0(X_test)\n",
        "y_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mya115eBk3Jx",
        "outputId": "4ced8224-3f77-4bff-d454-e79d6e5d327c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.8685],\n",
              "        [0.8825],\n",
              "        [0.8965],\n",
              "        [0.9105],\n",
              "        [0.9245],\n",
              "        [0.9384],\n",
              "        [0.9524],\n",
              "        [0.9664],\n",
              "        [0.9804],\n",
              "        [0.9944]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_predictions(predictions=y_preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "Qo0BzgxWm3Bm",
        "outputId": "716b3517-78c2-40fd-997d-af12569df8be"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "# Creating models directory\n",
        "MODEL_PATH=Path(\"models\")\n",
        "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
        "# CREATE model save path\n",
        "MODEL_NAME = \"pytorch_workflow_model.pth\"\n",
        "MODEL_SAVE_PATH = MODEL_PATH/MODEL_NAME\n",
        "# Saving the model state dict\n",
        "print(f\"Saving model to :{MODEL_SAVE_PATH}\")\n",
        "torch.save(obj=model_0.state_dict(), # Only saving the state_dict() only saves the model learneed parameters\n",
        "           f=MODEL_SAVE_PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0Q1Py4Mm8O_",
        "outputId": "f663ac50-d614-4f57-fc25-126edbe2a4fd"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model to :models/pytorch_workflow_model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# checking the saved file path\n",
        "!ls -l models/pytorch_workflow_model.pth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSdlk9kqpDYQ",
        "outputId": "5ce7baee-c3dd-4b08-eaa1-41ad003778e4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root root 1650 Feb 27 12:57 models/pytorch_workflow_model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iN0CxV1JpMZ8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}